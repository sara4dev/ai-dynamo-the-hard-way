{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Module 01: Setup and First Inference\n",
        "\n",
        "> **Goal**: Get Dynamo running and make your first inference request in under 15 minutes.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Verify Your Environment\n",
        "\n",
        "Let's make sure we have the basics: GPU, Python, and network access."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "ENVIRONMENT CHECK\n",
            "============================================================\n",
            "\n",
            "‚úì Python: 3.12.3\n",
            "‚úì GPU: NVIDIA GB10, [N/A], 580.95.05\n",
            "‚úì CUDA: 13.0, V13.0.88\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Quick environment check\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"ENVIRONMENT CHECK\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Python version\n",
        "print(f\"\\n‚úì Python: {sys.version.split()[0]}\")\n",
        "\n",
        "# GPU check\n",
        "try:\n",
        "    result = subprocess.run(\n",
        "        ['nvidia-smi', '--query-gpu=name,memory.total,driver_version', '--format=csv,noheader'],\n",
        "        capture_output=True, text=True, timeout=5\n",
        "    )\n",
        "    if result.returncode == 0:\n",
        "        for line in result.stdout.strip().split('\\n'):\n",
        "            print(f\"‚úì GPU: {line}\")\n",
        "    else:\n",
        "        print(\"‚úó No GPU detected\")\n",
        "except Exception as e:\n",
        "    print(f\"‚úó GPU check failed: {e}\")\n",
        "\n",
        "# CUDA check\n",
        "try:\n",
        "    result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True, timeout=5)\n",
        "    if result.returncode == 0:\n",
        "        cuda_version = [l for l in result.stdout.split('\\n') if 'release' in l][0]\n",
        "        print(f\"‚úì CUDA: {cuda_version.split('release')[-1].strip().rstrip(',').strip()}\")\n",
        "except:\n",
        "    print(\"! CUDA toolkit not found (may still work with runtime)\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Step 2: Install Dynamo\n",
        "\n",
        "Dynamo can be installed from PyPI. We'll use SGLang as our inference backend."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "============================================================\n",
            "Verifying installation...\n",
            "============================================================\n",
            "‚úì Dynamo Python package imported successfully\n",
            "‚úì PyTorch version: 2.9.1+cu130\n",
            "‚úì CUDA available: True\n",
            "‚úì CUDA device: NVIDIA GB10\n",
            "‚úì SGLang version: 0.5.6.post2\n"
          ]
        }
      ],
      "source": [
        "# Install Dynamo with SGLang (as per official quickstart)\n",
        "# Note: This may take a few minutes\n",
        "\n",
        "%pip install \"ai-dynamo[sglang]\" --quiet\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Verifying installation...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Verify Python imports\n",
        "try:\n",
        "    import dynamo\n",
        "    print(f\"‚úì Dynamo Python package imported successfully\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚úó Dynamo import failed: {e}\")\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    print(f\"‚úì PyTorch version: {torch.__version__}\")\n",
        "    print(f\"‚úì CUDA available: {torch.cuda.is_available()}\")\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"‚úì CUDA device: {torch.cuda.get_device_name(0)}\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚úó PyTorch import failed: {e}\")\n",
        "\n",
        "try:\n",
        "    import sglang\n",
        "    print(f\"‚úì SGLang version: {sglang.__version__}\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚úó SGLang import failed: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Step 3: Start Infrastructure (etcd + NATS)\n",
        "\n",
        "Dynamo needs two services running:\n",
        "- **etcd**: Service discovery (workers register here)\n",
        "- **NATS**: Event messaging (KV cache notifications)\n",
        "\n",
        "We'll use Docker for quick setup:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì etcd already running\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì NATS already running\n",
            "\n",
            "Infrastructure status:\n",
            "NAMES         STATUS          PORTS\n",
            "dynamo-nats   Up 48 minutes   0.0.0.0:4222->4222/tcp, [::]:4222->4222/tcp, 0.0.0.0:8222->8222/tcp, [::]:8222->8222/tcp, 6222/tcp\n",
            "dynamo-etcd   Up 48 minutes   0.0.0.0:2379-2380->2379-2380/tcp, [::]:2379-2380->2379-2380/tcp\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "# Start etcd if not running\n",
        "if ! docker ps | grep -q dynamo-etcd; then\n",
        "    echo \"Starting etcd...\"\n",
        "    docker run -d \\\n",
        "        --name dynamo-etcd \\\n",
        "        --restart unless-stopped \\\n",
        "        -p 2379:2379 \\\n",
        "        -p 2380:2380 \\\n",
        "        quay.io/coreos/etcd:v3.5.17 \\\n",
        "        /usr/local/bin/etcd \\\n",
        "        --name etcd0 \\\n",
        "        --advertise-client-urls http://0.0.0.0:2379 \\\n",
        "        --listen-client-urls http://0.0.0.0:2379 \\\n",
        "        --initial-advertise-peer-urls http://0.0.0.0:2380 \\\n",
        "        --listen-peer-urls http://0.0.0.0:2380 \\\n",
        "        --initial-cluster etcd0=http://0.0.0.0:2380\n",
        "    echo \"‚úì etcd started\"\n",
        "else\n",
        "    echo \"‚úì etcd already running\"\n",
        "fi\n",
        "\n",
        "# Start NATS if not running\n",
        "if ! docker ps | grep -q dynamo-nats; then\n",
        "    echo \"Starting NATS...\"\n",
        "    docker run -d \\\n",
        "        --name dynamo-nats \\\n",
        "        --restart unless-stopped \\\n",
        "        -p 4222:4222 \\\n",
        "        -p 8222:8222 \\\n",
        "        nats:latest \\\n",
        "        -js -m 8222\n",
        "    echo \"‚úì NATS started\"\n",
        "else\n",
        "    echo \"‚úì NATS already running\"\n",
        "fi\n",
        "\n",
        "# Wait for services to be ready\n",
        "sleep 2\n",
        "echo \"\"\n",
        "echo \"Infrastructure status:\"\n",
        "docker ps --format \"table {{.Names}}\\t{{.Status}}\\t{{.Ports}}\" | grep -E \"(NAMES|dynamo)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking service health...\n",
            "\n",
            "‚úì etcd: {'health': 'true', 'reason': ''}\n",
            "‚úì NATS: {\"status\":\"ok\"}\n"
          ]
        }
      ],
      "source": [
        "# Verify services are responding\n",
        "import urllib.request\n",
        "import json\n",
        "\n",
        "print(\"Checking service health...\\n\")\n",
        "\n",
        "# Check etcd\n",
        "try:\n",
        "    with urllib.request.urlopen('http://localhost:2379/health', timeout=5) as response:\n",
        "        data = json.loads(response.read())\n",
        "        print(f\"‚úì etcd: {data}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚úó etcd not responding: {e}\")\n",
        "\n",
        "# Check NATS\n",
        "try:\n",
        "    with urllib.request.urlopen('http://localhost:8222/healthz', timeout=5) as response:\n",
        "        status = response.read().decode()\n",
        "        print(f\"‚úì NATS: {status}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚úó NATS not responding: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Step 4: Download a Model\n",
        "\n",
        "We'll use a small model for quick testing: **Qwen3-0.6B**\n",
        "\n",
        "This is small enough to load quickly but demonstrates all Dynamo functionality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: Qwen/Qwen3-0.6B\n",
            "\n",
            "This model will be downloaded on first use.\n",
            "For faster testing, we'll let the backend handle the download.\n"
          ]
        }
      ],
      "source": [
        "# Model configuration\n",
        "MODEL_NAME = \"Qwen/Qwen3-0.6B\"\n",
        "\n",
        "print(f\"Model: {MODEL_NAME}\")\n",
        "print(\"\\nThis model will be downloaded on first use.\")\n",
        "print(\"For faster testing, we'll let the backend handle the download.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Step 5: Start Dynamo Frontend and Worker\n",
        "\n",
        "Dynamo uses a disaggregated architecture with separate frontend and worker processes:\n",
        "- **Frontend**: Handles HTTP requests and routes to workers\n",
        "- **Worker**: Runs the model inference (vLLM backend)\n",
        "\n",
        "The cell below will start both processes in the background:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 602625Started Dynamo frontend and vLLM worker in background\n",
            "Wait ~30s for the model to load before continuing\n",
            "Check logs: /tmp/dynamo_frontend.log and /tmp/dynamo_worker.log\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "# Kill any existing Dynamo processes and free port 8000\n",
        "pkill -f 'python -m dynamo' 2>/dev/null || true\n",
        "fuser -k 8000/tcp 2>/dev/null || true\n",
        "sleep 2\n",
        "\n",
        "# Start the frontend\n",
        "python -m dynamo.frontend > /tmp/dynamo_frontend.log 2>&1 &\n",
        "\n",
        "# Start the SGLang worker\n",
        "python -m dynamo.sglang --model-path Qwen/Qwen3-0.6B > /tmp/dynamo_worker.log 2>&1 &\n",
        "\n",
        "echo \"Started Dynamo frontend and SGLang worker in background\"\n",
        "echo \"Wait ~30s for the model to load before continuing\"\n",
        "echo \"Check logs: /tmp/dynamo_frontend.log and /tmp/dynamo_worker.log\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Waiting for Dynamo to start...\n",
            "\n",
            "=== Frontend Log (last 20 lines) ===\n",
            "\u001b[2m2026-02-01T19:47:40.738379Z\u001b[0m \u001b[32m INFO\u001b[0m \u001b[2mdynamo_runtime::distributed\u001b[0m\u001b[2m:\u001b[0m Initializing KV store discovery backend\n",
            "\u001b[2m2026-02-01T19:47:40.738508Z\u001b[0m \u001b[32m INFO\u001b[0m \u001b[2mdynamo_runtime::pipeline::network::manager\u001b[0m\u001b[2m:\u001b[0m Initializing NetworkManager with TCP request plane \u001b[3mmode\u001b[0m\u001b[2m=\u001b[0mtcp \u001b[3mhost\u001b[0m\u001b[2m=\u001b[0m192.168.1.76 \u001b[3mport\u001b[0m\u001b[2m=\u001b[0mOS-assigned\n",
            "\u001b[2m2026-02-01T19:47:40.739994Z\u001b[0m \u001b[32m INFO\u001b[0m \u001b[2mdynamo_llm::http::service::service_v2\u001b[0m\u001b[2m:\u001b[0m Starting HTTP(S) service \u001b[3mprotocol\u001b[0m\u001b[2m=\u001b[0m\"HTTP\" \u001b[3maddress\u001b[0m\u001b[2m=\u001b[0m\"0.0.0.0:8000\"\n",
            "\n",
            "=== Worker Log (last 20 lines) ===\n",
            "    from .communication_op import *\n",
            "  File \"/root/src/github.com/sara4dev/ai-dynamo-the-hard-way/.venv/lib/python3.12/site-packages/vllm/distributed/communication_op.py\", line 9, in <module>\n",
            "    from .parallel_state import get_tp_group\n",
            "  File \"/root/src/github.com/sara4dev/ai-dynamo-the-hard-way/.venv/lib/python3.12/site-packages/vllm/distributed/parallel_state.py\", line 250, in <module>\n",
            "    direct_register_custom_op(\n",
            "  File \"/root/src/github.com/sara4dev/ai-dynamo-the-hard-way/.venv/lib/python3.12/site-packages/vllm/utils/torch_utils.py\", line 637, in direct_register_custom_op\n",
            "    from vllm.platforms import current_platform\n",
            "  File \"/root/src/github.com/sara4dev/ai-dynamo-the-hard-way/.venv/lib/python3.12/site-packages/vllm/platforms/__init__.py\", line 257, in __getattr__\n",
            "    _current_platform = resolve_obj_by_qualname(platform_cls_qualname)()\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/root/src/github.com/sara4dev/ai-dynamo-the-hard-way/.venv/lib/python3.12/site-packages/vllm/utils/import_utils.py\", line 122, in resolve_obj_by_qualname\n",
            "    module = importlib.import_module(module_name)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/importlib/__init__.py\", line 90, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/root/src/github.com/sara4dev/ai-dynamo-the-hard-way/.venv/lib/python3.12/site-packages/vllm/platforms/cuda.py\", line 16, in <module>\n",
            "    import vllm._C  # noqa\n",
            "    ^^^^^^^^^^^^^^\n",
            "ImportError: libtorch_cuda.so: cannot open shared object file: No such file or directory\n",
            "\n",
            "=== Health Check ===\n",
            "{\"status\":\"healthy\",\"endpoints\":[],\"instances\":[]} - Frontend is UP\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "# Wait for services to start and check logs\n",
        "echo \"Waiting for Dynamo to start...\"\n",
        "sleep 10\n",
        "\n",
        "echo \"\"\n",
        "echo \"=== Frontend Log (last 20 lines) ===\"\n",
        "tail -20 /tmp/dynamo_frontend.log 2>/dev/null || echo \"No frontend log yet\"\n",
        "\n",
        "echo \"\"\n",
        "echo \"=== Worker Log (last 20 lines) ===\"\n",
        "tail -20 /tmp/dynamo_worker.log 2>/dev/null || echo \"No worker log yet\"\n",
        "\n",
        "echo \"\"\n",
        "echo \"=== Health Check ===\"\n",
        "curl -s http://localhost:8000/health && echo \" - Frontend is UP\" || echo \"Frontend not responding yet\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Step 6: Your First Inference Request! üéâ\n",
        "\n",
        "Now let's send a request using the OpenAI-compatible API:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "import json\n",
        "import time\n",
        "\n",
        "# Dynamo endpoint\n",
        "DYNAMO_URL = \"http://localhost:8000/v1/chat/completions\"\n",
        "\n",
        "# Request payload (OpenAI-compatible format)\n",
        "payload = {\n",
        "    \"model\": \"Qwen/Qwen3-0.6B\",\n",
        "    \"messages\": [\n",
        "        {\"role\": \"user\", \"content\": \"What is the capital of France? Answer in one sentence.\"}\n",
        "    ],\n",
        "    \"max_tokens\": 50,\n",
        "    \"temperature\": 0.7\n",
        "}\n",
        "\n",
        "print(\"Sending request to Dynamo...\")\n",
        "print(f\"Prompt: {payload['messages'][0]['content']}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "try:\n",
        "    req = urllib.request.Request(\n",
        "        DYNAMO_URL,\n",
        "        data=json.dumps(payload).encode(),\n",
        "        headers={'Content-Type': 'application/json'}\n",
        "    )\n",
        "    with urllib.request.urlopen(req, timeout=60) as response:\n",
        "        result = json.loads(response.read())\n",
        "        \n",
        "    elapsed = time.time() - start_time\n",
        "    \n",
        "    # Extract response\n",
        "    answer = result['choices'][0]['message']['content']\n",
        "    usage = result.get('usage', {})\n",
        "    \n",
        "    print(f\"\\n‚úì Response received in {elapsed:.2f}s\")\n",
        "    print(f\"\\nAnswer: {answer}\")\n",
        "    print(f\"\\nTokens: {usage.get('prompt_tokens', '?')} prompt + {usage.get('completion_tokens', '?')} completion\")\n",
        "    \n",
        "except urllib.error.URLError as e:\n",
        "    print(f\"\\n‚úó Connection failed: {e}\")\n",
        "    print(\"\\nMake sure the Dynamo worker is running (Step 5)\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚úó Error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Step 7: Test Streaming Response\n",
        "\n",
        "Dynamo supports streaming for real-time token generation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "import json\n",
        "import time\n",
        "\n",
        "DYNAMO_URL = \"http://localhost:8000/v1/chat/completions\"\n",
        "\n",
        "payload = {\n",
        "    \"model\": \"Qwen/Qwen3-0.6B\",\n",
        "    \"messages\": [\n",
        "        {\"role\": \"user\", \"content\": \"Count from 1 to 10, one number per line.\"}\n",
        "    ],\n",
        "    \"max_tokens\": 100,\n",
        "    \"stream\": True  # Enable streaming\n",
        "}\n",
        "\n",
        "print(\"Streaming response:\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "start_time = time.time()\n",
        "first_token_time = None\n",
        "\n",
        "try:\n",
        "    req = urllib.request.Request(\n",
        "        DYNAMO_URL,\n",
        "        data=json.dumps(payload).encode(),\n",
        "        headers={'Content-Type': 'application/json'}\n",
        "    )\n",
        "    \n",
        "    with urllib.request.urlopen(req, timeout=60) as response:\n",
        "        for line in response:\n",
        "            line = line.decode().strip()\n",
        "            if line.startswith('data: '):\n",
        "                data = line[6:]  # Remove 'data: ' prefix\n",
        "                if data == '[DONE]':\n",
        "                    break\n",
        "                try:\n",
        "                    chunk = json.loads(data)\n",
        "                    delta = chunk['choices'][0].get('delta', {})\n",
        "                    content = delta.get('content', '')\n",
        "                    if content:\n",
        "                        if first_token_time is None:\n",
        "                            first_token_time = time.time()\n",
        "                        print(content, end='', flush=True)\n",
        "                except json.JSONDecodeError:\n",
        "                    pass\n",
        "    \n",
        "    total_time = time.time() - start_time\n",
        "    ttft = first_token_time - start_time if first_token_time else 0\n",
        "    \n",
        "    print(f\"\\n\\n\" + \"-\" * 50)\n",
        "    print(f\"Time to First Token (TTFT): {ttft:.3f}s\")\n",
        "    print(f\"Total time: {total_time:.2f}s\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"\\n‚úó Error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Step 8: Verify System State\n",
        "\n",
        "Let's check the full system status:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"SYSTEM STATUS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# GPU utilization\n",
        "print(\"\\nüìä GPU Status:\")\n",
        "!nvidia-smi --query-gpu=name,memory.used,memory.total,utilization.gpu --format=csv\n",
        "\n",
        "# Docker containers\n",
        "print(\"\\nüê≥ Infrastructure Containers:\")\n",
        "!docker ps --filter name=dynamo --format \"table {{.Names}}\\t{{.Status}}\\t{{.Ports}}\"\n",
        "\n",
        "# Health endpoints\n",
        "print(\"\\nüè• Health Checks:\")\n",
        "import urllib.request\n",
        "import json\n",
        "\n",
        "services = [\n",
        "    (\"Dynamo Frontend\", \"http://localhost:8000/health\"),\n",
        "    (\"etcd\", \"http://localhost:2379/health\"),\n",
        "    (\"NATS\", \"http://localhost:8222/healthz\"),\n",
        "]\n",
        "\n",
        "for name, url in services:\n",
        "    try:\n",
        "        with urllib.request.urlopen(url, timeout=2) as resp:\n",
        "            print(f\"  ‚úì {name}: OK\")\n",
        "    except:\n",
        "        print(f\"  ‚úó {name}: Not responding\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üéâ Congratulations!\n",
        "\n",
        "You now have a working Dynamo setup:\n",
        "\n",
        "| Component | Status | Port |\n",
        "|-----------|--------|------|\n",
        "| etcd (Service Discovery) | Running | 2379 |\n",
        "| NATS (Messaging) | Running | 4222 |\n",
        "| Dynamo Worker (SGLang) | Running | 8000 |\n",
        "\n",
        "### What's Next?\n",
        "\n",
        "- **Module 02**: Deep dive into the Frontend (HTTP handling, routing)\n",
        "- **Module 03**: Compare different backends (vLLM, SGLang, TensorRT-LLM)\n",
        "- **Module 04**: Understanding etcd service discovery in detail"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Cleanup (Optional)\n",
        "\n",
        "Run this cell to stop the Dynamo processes when you're done:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "# Stop Dynamo processes\n",
        "pkill -f 'python -m dynamo' || true\n",
        "echo \"Dynamo processes stopped\"\n",
        "\n",
        "# Uncomment below to also stop infrastructure containers\n",
        "# docker stop dynamo-etcd dynamo-nats\n",
        "# docker rm dynamo-etcd dynamo-nats"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
