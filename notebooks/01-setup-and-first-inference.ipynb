{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Module 01: Setup and First Inference\n",
        "\n",
        "> **Goal**: Get Dynamo running and make your first inference request in under 15 minutes.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Verify Your Environment\n",
        "\n",
        "Let's make sure we have the basics: GPU, Python, and network access."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "ENVIRONMENT CHECK\n",
            "============================================================\n",
            "\n",
            "âœ“ Python: 3.12.3\n",
            "âœ“ GPU: NVIDIA GeForce RTX 5090, 32607 MiB, 580.105.08\n",
            "âœ“ GPU: NVIDIA GeForce RTX 5090, 32607 MiB, 580.105.08\n",
            "! CUDA toolkit not found (may still work with runtime)\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Quick environment check\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"ENVIRONMENT CHECK\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Python version\n",
        "print(f\"\\nâœ“ Python: {sys.version.split()[0]}\")\n",
        "\n",
        "# GPU check\n",
        "try:\n",
        "    result = subprocess.run(\n",
        "        ['nvidia-smi', '--query-gpu=name,memory.total,driver_version', '--format=csv,noheader'],\n",
        "        capture_output=True, text=True, timeout=5\n",
        "    )\n",
        "    if result.returncode == 0:\n",
        "        for line in result.stdout.strip().split('\\n'):\n",
        "            print(f\"âœ“ GPU: {line}\")\n",
        "    else:\n",
        "        print(\"âœ— No GPU detected\")\n",
        "except Exception as e:\n",
        "    print(f\"âœ— GPU check failed: {e}\")\n",
        "\n",
        "# CUDA check\n",
        "try:\n",
        "    result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True, timeout=5)\n",
        "    if result.returncode == 0:\n",
        "        cuda_version = [l for l in result.stdout.split('\\n') if 'release' in l][0]\n",
        "        print(f\"âœ“ CUDA: {cuda_version.split('release')[-1].strip().rstrip(',').strip()}\")\n",
        "except:\n",
        "    print(\"! CUDA toolkit not found (may still work with runtime)\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Step 2: Install Dynamo\n",
        "\n",
        "Dynamo can be installed from PyPI. We'll use SGLang as our inference backend."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/root/src/github.com/sara4dev/ai-dynamo-the-hard-way/.venv/bin/python: No module named uv\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "============================================================\n",
            "Verifying installation...\n",
            "============================================================\n",
            "âœ“ Dynamo Python package imported successfully\n",
            "âœ“ PyTorch version: 2.9.1+cu128\n",
            "âœ“ CUDA available: True\n",
            "âœ“ CUDA device: NVIDIA GeForce RTX 5090\n",
            "âœ“ SGLang version: 0.5.6.post2\n"
          ]
        }
      ],
      "source": [
        "# Install Dynamo with SGLang (as per official quickstart)\n",
        "# Note: This may take a few minutes\n",
        "\n",
        "%uv pip install \"ai-dynamo[sglang]\"\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Verifying installation...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Verify Python imports\n",
        "try:\n",
        "    import dynamo\n",
        "    print(f\"âœ“ Dynamo Python package imported successfully\")\n",
        "except ImportError as e:\n",
        "    print(f\"âœ— Dynamo import failed: {e}\")\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    print(f\"âœ“ PyTorch version: {torch.__version__}\")\n",
        "    print(f\"âœ“ CUDA available: {torch.cuda.is_available()}\")\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"âœ“ CUDA device: {torch.cuda.get_device_name(0)}\")\n",
        "except ImportError as e:\n",
        "    print(f\"âœ— PyTorch import failed: {e}\")\n",
        "\n",
        "try:\n",
        "    import sglang\n",
        "    print(f\"âœ“ SGLang version: {sglang.__version__}\")\n",
        "except ImportError as e:\n",
        "    print(f\"âœ— SGLang import failed: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Step 3: Start Infrastructure (etcd + NATS)\n",
        "\n",
        "Dynamo needs two services running:\n",
        "- **etcd**: Service discovery (workers register here)\n",
        "- **NATS**: Event messaging (KV cache notifications)\n",
        "\n",
        "We'll use Docker for quick setup:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ etcd already running\n",
            "âœ“ NATS already running\n",
            "\n",
            "Infrastructure status:\n",
            "NAMES         STATUS          PORTS\n",
            "dynamo-nats   Up 41 minutes   0.0.0.0:4222->4222/tcp, [::]:4222->4222/tcp, 0.0.0.0:8222->8222/tcp, [::]:8222->8222/tcp, 6222/tcp\n",
            "dynamo-etcd   Up 41 minutes   0.0.0.0:2379-2380->2379-2380/tcp, [::]:2379-2380->2379-2380/tcp\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "# Start etcd if not running\n",
        "if ! docker ps | grep -q dynamo-etcd; then\n",
        "    echo \"Starting etcd...\"\n",
        "    docker run -d \\\n",
        "        --name dynamo-etcd \\\n",
        "        --restart unless-stopped \\\n",
        "        -p 2379:2379 \\\n",
        "        -p 2380:2380 \\\n",
        "        quay.io/coreos/etcd:v3.5.17 \\\n",
        "        /usr/local/bin/etcd \\\n",
        "        --name etcd0 \\\n",
        "        --advertise-client-urls http://0.0.0.0:2379 \\\n",
        "        --listen-client-urls http://0.0.0.0:2379 \\\n",
        "        --initial-advertise-peer-urls http://0.0.0.0:2380 \\\n",
        "        --listen-peer-urls http://0.0.0.0:2380 \\\n",
        "        --initial-cluster etcd0=http://0.0.0.0:2380\n",
        "    echo \"âœ“ etcd started\"\n",
        "else\n",
        "    echo \"âœ“ etcd already running\"\n",
        "fi\n",
        "\n",
        "# Start NATS if not running\n",
        "if ! docker ps | grep -q dynamo-nats; then\n",
        "    echo \"Starting NATS...\"\n",
        "    docker run -d \\\n",
        "        --name dynamo-nats \\\n",
        "        --restart unless-stopped \\\n",
        "        -p 4222:4222 \\\n",
        "        -p 8222:8222 \\\n",
        "        nats:latest \\\n",
        "        -js -m 8222\n",
        "    echo \"âœ“ NATS started\"\n",
        "else\n",
        "    echo \"âœ“ NATS already running\"\n",
        "fi\n",
        "\n",
        "# Wait for services to be ready\n",
        "sleep 2\n",
        "echo \"\"\n",
        "echo \"Infrastructure status:\"\n",
        "docker ps --format \"table {{.Names}}\\t{{.Status}}\\t{{.Ports}}\" | grep -E \"(NAMES|dynamo)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking service health...\n",
            "\n",
            "âœ“ etcd: {'health': 'true', 'reason': ''}\n",
            "âœ“ NATS: {\"status\":\"ok\"}\n"
          ]
        }
      ],
      "source": [
        "# Verify services are responding\n",
        "import urllib.request\n",
        "import json\n",
        "\n",
        "print(\"Checking service health...\\n\")\n",
        "\n",
        "# Check etcd\n",
        "try:\n",
        "    with urllib.request.urlopen('http://localhost:2379/health', timeout=5) as response:\n",
        "        data = json.loads(response.read())\n",
        "        print(f\"âœ“ etcd: {data}\")\n",
        "except Exception as e:\n",
        "    print(f\"âœ— etcd not responding: {e}\")\n",
        "\n",
        "# Check NATS\n",
        "try:\n",
        "    with urllib.request.urlopen('http://localhost:8222/healthz', timeout=5) as response:\n",
        "        status = response.read().decode()\n",
        "        print(f\"âœ“ NATS: {status}\")\n",
        "except Exception as e:\n",
        "    print(f\"âœ— NATS not responding: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Step 4: Download a Model\n",
        "\n",
        "We'll use a small model for quick testing: **Qwen3-0.6B**\n",
        "\n",
        "This is small enough to load quickly but demonstrates all Dynamo functionality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: Qwen/Qwen3-0.6B\n",
            "\n",
            "This model will be downloaded on first use.\n",
            "For faster testing, we'll let the backend handle the download.\n"
          ]
        }
      ],
      "source": [
        "# Model configuration\n",
        "MODEL_NAME = \"Qwen/Qwen3-0.6B\"\n",
        "\n",
        "print(f\"Model: {MODEL_NAME}\")\n",
        "print(\"\\nThis model will be downloaded on first use.\")\n",
        "print(\"For faster testing, we'll let the backend handle the download.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Step 5: Start Dynamo Frontend and Worker\n",
        "\n",
        "Dynamo uses a disaggregated architecture with separate frontend and worker processes:\n",
        "- **Frontend**: Handles HTTP requests and routes to workers\n",
        "- **Worker**: Runs the model inference (vLLM backend)\n",
        "\n",
        "The cell below will start both processes in the background:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Killing any existing Dynamo processes...\n",
            "Starting Dynamo frontend...\n",
            "Starting Dynamo worker...\n",
            "Started Dynamo frontend and SGLang worker in background\n",
            "Wait ~30s for the model to load before continuing\n",
            "Check logs: /tmp/dynamo_frontend.log and /tmp/dynamo_worker.log\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "# Kill any existing Dynamo processes and free port 8000\n",
        "echo \"Killing any existing Dynamo processes...\"\n",
        "pkill -f 'python -m dynamo' 2>/dev/null || true\n",
        "fuser -k 8000/tcp 2>/dev/null || true\n",
        "sleep 30\n",
        "\n",
        "# Start the frontend\n",
        "echo \"Starting Dynamo frontend...\"\n",
        "python -m dynamo.frontend > /tmp/dynamo_frontend.log 2>&1 &\n",
        "\n",
        "# Start the SGLang worker\n",
        "echo \"Starting Dynamo worker...\"\n",
        "# attention backend flashinfer works with RTX 5090\n",
        "python -m dynamo.sglang --model-path Qwen/Qwen3-0.6B --attention-backend flashinfer > /tmp/dynamo_worker.log 2>&1 &\n",
        "\n",
        "echo \"Started Dynamo frontend and SGLang worker in background\"\n",
        "echo \"Wait ~30s for the model to load before continuing\"\n",
        "echo \"Check logs: /tmp/dynamo_frontend.log and /tmp/dynamo_worker.log\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Waiting for Dynamo to start...\n",
            "[0s] âœ“ Frontend is READY (status: healthy)\n",
            "[0s] âœ“ Backend is READY (endpoints registered)\n",
            "\n",
            "=== Final Health Status ===\n",
            "{\n",
            "  \"status\": \"healthy\",\n",
            "  \"endpoints\": [\n",
            "    \"dyn://dynamo.backend.generate\"\n",
            "  ],\n",
            "  \"instances\": [\n",
            "    {\n",
            "      \"component\": \"backend\",\n",
            "      \"endpoint\": \"generate\",\n",
            "      \"namespace\": \"dynamo\",\n",
            "      \"instance_id\": 112480155747070545,\n",
            "      \"transport\": {\n",
            "        \"tcp\": \"192.168.1.180:44159/18f9c1b0f95b251/generate\"\n",
            "      }\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\n",
            "=== Dynamo is fully operational! ===\n"
          ]
        }
      ],
      "source": [
        "import urllib.request\n",
        "import json\n",
        "import time\n",
        "\n",
        "print(\"Waiting for Dynamo to start...\")\n",
        "\n",
        "MAX_WAIT = 300  # Maximum wait time in seconds\n",
        "INTERVAL = 5    # Check interval in seconds\n",
        "elapsed = 0\n",
        "frontend_ready = False\n",
        "backend_ready = False\n",
        "\n",
        "while elapsed < MAX_WAIT:\n",
        "    try:\n",
        "        with urllib.request.urlopen('http://localhost:8000/health', timeout=5) as response:\n",
        "            health = json.loads(response.read())\n",
        "            \n",
        "            # Check if frontend is healthy\n",
        "            if health.get('status') == 'healthy' and not frontend_ready:\n",
        "                print(f\"[{elapsed}s] âœ“ Frontend is READY (status: healthy)\")\n",
        "                frontend_ready = True\n",
        "            \n",
        "            # Check if backend endpoint is registered\n",
        "            endpoints = health.get('endpoints', [])\n",
        "            has_backend = any('backend' in ep for ep in endpoints)\n",
        "            \n",
        "            if has_backend:\n",
        "                print(f\"[{elapsed}s] âœ“ Backend is READY (endpoints registered)\")\n",
        "                print()\n",
        "                print(\"=== Final Health Status ===\")\n",
        "                print(json.dumps(health, indent=2))\n",
        "                backend_ready = True\n",
        "                break\n",
        "            elif frontend_ready:\n",
        "                print(f\"[{elapsed}s] Waiting for backend endpoints... (frontend healthy, no backend yet)\")\n",
        "                \n",
        "    except Exception as e:\n",
        "        print(f\"[{elapsed}s] Waiting for frontend to respond...\")\n",
        "    \n",
        "    time.sleep(INTERVAL)\n",
        "    elapsed += INTERVAL\n",
        "\n",
        "if not backend_ready:\n",
        "    print()\n",
        "    print(f\"=== Timeout after {MAX_WAIT}s ===\")\n",
        "    print(f\"Frontend ready: {frontend_ready}\")\n",
        "    print(f\"Backend ready: {backend_ready}\")\n",
        "    print()\n",
        "    print(\"=== Frontend Log (last 20 lines) ===\")\n",
        "    try:\n",
        "        with open('/tmp/dynamo_frontend.log', 'r') as f:\n",
        "            lines = f.readlines()\n",
        "            print(''.join(lines[-20:]))\n",
        "    except:\n",
        "        print(\"No frontend log yet\")\n",
        "    print()\n",
        "    print(\"=== Worker Log (last 20 lines) ===\")\n",
        "    try:\n",
        "        with open('/tmp/dynamo_worker.log', 'r') as f:\n",
        "            lines = f.readlines()\n",
        "            print(''.join(lines[-20:]))\n",
        "    except:\n",
        "        print(\"No worker log yet\")\n",
        "else:\n",
        "    print()\n",
        "    print(\"=== Dynamo is fully operational! ===\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Step 6: Your First Inference Request! ðŸŽ‰\n",
        "\n",
        "Now let's send a request using the OpenAI-compatible API:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sending request to Dynamo...\n",
            "Prompt: What is the capital of France? Answer in one sentence.\n",
            "--------------------------------------------------\n",
            "\n",
            "âœ“ Response received in 3.67s\n",
            "\n",
            "Answer: <think>\n",
            "Okay, the user is asking for the capital of France in one sentence. I need to make sure I recall the correct answer. France's capital is Paris. Let me double-check that. Yes, Paris is the capital. I should state\n",
            "\n",
            "Tokens: 20 prompt + 50 completion\n"
          ]
        }
      ],
      "source": [
        "import urllib.request\n",
        "import json\n",
        "import time\n",
        "\n",
        "# Dynamo endpoint\n",
        "DYNAMO_URL = \"http://localhost:8000/v1/chat/completions\"\n",
        "\n",
        "# Request payload (OpenAI-compatible format)\n",
        "payload = {\n",
        "    \"model\": \"Qwen/Qwen3-0.6B\",\n",
        "    \"messages\": [\n",
        "        {\"role\": \"user\", \"content\": \"What is the capital of France? Answer in one sentence.\"}\n",
        "    ],\n",
        "    \"max_tokens\": 50,\n",
        "    \"temperature\": 0.7\n",
        "}\n",
        "\n",
        "print(\"Sending request to Dynamo...\")\n",
        "print(f\"Prompt: {payload['messages'][0]['content']}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "try:\n",
        "    req = urllib.request.Request(\n",
        "        DYNAMO_URL,\n",
        "        data=json.dumps(payload).encode(),\n",
        "        headers={'Content-Type': 'application/json'}\n",
        "    )\n",
        "    with urllib.request.urlopen(req, timeout=60) as response:\n",
        "        result = json.loads(response.read())\n",
        "        \n",
        "    elapsed = time.time() - start_time\n",
        "    \n",
        "    # Extract response\n",
        "    answer = result['choices'][0]['message']['content']\n",
        "    usage = result.get('usage', {})\n",
        "    \n",
        "    print(f\"\\nâœ“ Response received in {elapsed:.2f}s\")\n",
        "    print(f\"\\nAnswer: {answer}\")\n",
        "    print(f\"\\nTokens: {usage.get('prompt_tokens', '?')} prompt + {usage.get('completion_tokens', '?')} completion\")\n",
        "    \n",
        "except urllib.error.URLError as e:\n",
        "    print(f\"\\nâœ— Connection failed: {e}\")\n",
        "    print(\"\\nMake sure the Dynamo worker is running (Step 5)\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nâœ— Error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Step 7: Verify System State\n",
        "\n",
        "Let's check the full system status:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "SYSTEM STATUS\n",
            "============================================================\n",
            "\n",
            "ðŸ“Š GPU Status:\n",
            "name, memory.used [MiB], memory.total [MiB], utilization.gpu [%]\n",
            "NVIDIA GeForce RTX 5090, 29808 MiB, 32607 MiB, 0 %\n",
            "NVIDIA GeForce RTX 5090, 4 MiB, 32607 MiB, 0 %\n",
            "\n",
            "ðŸ³ Infrastructure Containers:\n",
            "CONTAINER ID   IMAGE                         COMMAND                  CREATED          STATUS          PORTS                                                                                                NAMES\n",
            "2a2da28afc9d   nats:latest                   \"/nats-server -js -mâ€¦\"   51 minutes ago   Up 51 minutes   0.0.0.0:4222->4222/tcp, [::]:4222->4222/tcp, 0.0.0.0:8222->8222/tcp, [::]:8222->8222/tcp, 6222/tcp   dynamo-nats\n",
            "c150bb746ae1   quay.io/coreos/etcd:v3.5.17   \"/usr/local/bin/etcdâ€¦\"   51 minutes ago   Up 51 minutes   0.0.0.0:2379-2380->2379-2380/tcp, [::]:2379-2380->2379-2380/tcp                                      dynamo-etcd\n",
            "\n",
            "ðŸ¥ Health Checks:\n",
            "  âœ“ Dynamo Frontend: OK\n",
            "  âœ“ etcd: OK\n",
            "  âœ“ NATS: OK\n",
            "\n",
            "ðŸ‘· Registered Workers (from etcd):\n",
            "  âœ“ v1/instances/dynamo/backend/generate/18f9c1b0f95b251\n",
            "{\n",
            "    \"type\": \"Endpoint\",\n",
            "    \"component\": \"backend\",\n",
            "    \"endpoint\": \"generate\",\n",
            "    \"namespace\": \"dynamo\",\n",
            "    \"instance_id\": 112480155747070545,\n",
            "    \"transport\": {\n",
            "        \"tcp\": \"192.168.1.180:44159/18f9c1b0f95b251/generate\"\n",
            "    }\n",
            "}\n",
            "\n",
            "  âœ“ v1/mdc/dynamo/backend/generate/18f9c1b0f95b251\n",
            "{\n",
            "    \"type\": \"Model\",\n",
            "    \"namespace\": \"dynamo\",\n",
            "    \"component\": \"backend\",\n",
            "    \"endpoint\": \"generate\",\n",
            "    \"instance_id\": 112480155747070545,\n",
            "    \"card_json\": {\n",
            "        \"display_name\": \"Qwen/Qwen3-0.6B\",\n",
            "        \"slug\": \"qwen_qwen3-0_6b\",\n",
            "        \"source_path\": \"Qwen/Qwen3-0.6B\",\n",
            "        \"model_info\": {\n",
            "            \"hf_config_json\": {\n",
            "                \"path\": \"hf://Qwen/Qwen3-0.6B/config.json\",\n",
            "                \"checksum\": \"blake3:d873e9bb2bd54ebf6c4a60732887a57c33881cca4b0d92ec5107e9cc4f023660\"\n",
            "            }\n",
            "        },\n",
            "        \"tokenizer\": {\n",
            "            \"hf_tokenizer_json\": {\n",
            "                \"path\": \"hf://Qwen/Qwen3-0.6B/tokenizer.json\",\n",
            "                \"checksum\": \"blake3:b0cb923fc505fdf0a53f0287654fa26577d3f333d4134350da0a97664b228739\"\n",
            "            }\n",
            "        },\n",
            "        \"prompt_formatter\": {\n",
            "            \"hf_tokenizer_config_json\": {\n",
            "                \"path\": \"hf://Qwen/Qwen3-0.6B/tokenizer_config.json\",\n",
            "                \"checksum\": \"blake3:4422061cdcb205f75bc448b09f4017f8f2f92f172aeb2cf0248f4ce2f0f360e6\"\n",
            "            }\n",
            "        },\n",
            "        \"gen_config\": {\n",
            "            \"hf_generation_config_json\": {\n",
            "                \"path\": \"hf://Qwen/Qwen3-0.6B/generation_config.json\",\n",
            "                \"checksum\": \"blake3:18b891ec9627c101a441aec842f39c05d9f13df63b4cfd4226594941d977a9a6\"\n",
            "            }\n",
            "        },\n",
            "        \"context_length\": 40960,\n",
            "        \"kv_cache_block_size\": 1,\n",
            "        \"migration_limit\": 0,\n",
            "        \"model_type\": \"Chat | Completions\",\n",
            "        \"model_input\": \"Tokens\",\n",
            "        \"runtime_config\": {\n",
            "            \"total_kv_blocks\": 243193,\n",
            "            \"max_num_seqs\": null,\n",
            "            \"max_num_batched_tokens\": 16384,\n",
            "            \"tool_call_parser\": null,\n",
            "            \"reasoning_parser\": null,\n",
            "            \"data_parallel_size\": 1,\n",
            "            \"enable_local_indexer\": false,\n",
            "            \"disaggregated_endpoint\": {\n",
            "                \"bootstrap_host\": \"192.168.1.180\",\n",
            "                \"bootstrap_port\": 38629\n",
            "            }\n",
            "        },\n",
            "        \"media_decoder\": null,\n",
            "        \"media_fetcher\": null\n",
            "    }\n",
            "}\n",
            "\n",
            "\n",
            "ðŸ¤– Available Models:\n",
            "  âœ“ Qwen/Qwen3-0.6B\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "import urllib.request\n",
        "import json\n",
        "import base64\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"SYSTEM STATUS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# GPU utilization\n",
        "print(\"\\nðŸ“Š GPU Status:\")\n",
        "!nvidia-smi --query-gpu=name,memory.used,memory.total,utilization.gpu --format=csv\n",
        "\n",
        "# Docker containers\n",
        "print(\"\\nðŸ³ Infrastructure Containers:\")\n",
        "!docker ps --filter name=dynamo\n",
        "\n",
        "# Health endpoints\n",
        "print(\"\\nðŸ¥ Health Checks:\")\n",
        "\n",
        "services = [\n",
        "    (\"Dynamo Frontend\", \"http://localhost:8000/health\"),\n",
        "    (\"etcd\", \"http://localhost:2379/health\"),\n",
        "    (\"NATS\", \"http://localhost:8222/healthz\"),\n",
        "]\n",
        "\n",
        "for name, url in services:\n",
        "    try:\n",
        "        with urllib.request.urlopen(url, timeout=2) as resp:\n",
        "            print(f\"  âœ“ {name}: OK\")\n",
        "    except:\n",
        "        print(f\"  âœ— {name}: Not responding\")\n",
        "\n",
        "# Check registered workers in etcd\n",
        "# Dynamo registers workers under the \"v1/\" prefix with two key types:\n",
        "#   - v1/instances/... : Worker endpoint registration (transport info)\n",
        "#   - v1/mdc/...       : Model Card with model configuration details\n",
        "print(\"\\nðŸ‘· Registered Workers (from etcd):\")\n",
        "try:\n",
        "    # Query etcd for all keys under v1/ prefix\n",
        "    req = urllib.request.Request(\n",
        "        \"http://localhost:2379/v3/kv/range\",\n",
        "        data=json.dumps({\n",
        "            \"key\": base64.b64encode(b\"v1/\").decode(),\n",
        "            \"range_end\": base64.b64encode(b\"v10\").decode()  # range_end for prefix scan\n",
        "        }).encode(),\n",
        "        headers={'Content-Type': 'application/json'}\n",
        "    )\n",
        "    with urllib.request.urlopen(req, timeout=5) as resp:\n",
        "        data = json.loads(resp.read())\n",
        "        if 'kvs' in data and data['kvs']:\n",
        "            for kv in data['kvs']:\n",
        "                key = base64.b64decode(kv['key']).decode()\n",
        "                value = json.loads(base64.b64decode(kv['value']).decode())\n",
        "                print(f\"  âœ“ {key}\")\n",
        "                print(json.dumps(value, indent=4))\n",
        "                print()\n",
        "        else:\n",
        "            print(\"  âš  No workers registered yet (wait for model to load)\")\n",
        "except Exception as e:\n",
        "    print(f\"  âœ— Could not query etcd: {e}\")\n",
        "\n",
        "# Verify models endpoint (confirms worker is ready to serve)\n",
        "print(\"\\nðŸ¤– Available Models:\")\n",
        "try:\n",
        "    req = urllib.request.Request(\n",
        "        \"http://localhost:8000/v1/models\",\n",
        "        headers={'Content-Type': 'application/json'}\n",
        "    )\n",
        "    with urllib.request.urlopen(req, timeout=5) as resp:\n",
        "        models = json.loads(resp.read())\n",
        "        if models.get('data'):\n",
        "            for model in models['data']:\n",
        "                print(f\"  âœ“ {model.get('id', 'unknown')}\")\n",
        "        else:\n",
        "            print(\"  âš  No models available yet\")\n",
        "except Exception as e:\n",
        "    print(f\"  âœ— Could not query models: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Understanding the Communication Flow\n",
        "\n",
        "Looking at the etcd output above, you can see how Dynamo components discover and communicate with each other:\n",
        "\n",
        "```\n",
        "Client â”€â”€HTTPâ”€â”€â–¶ Frontend (:8000) â”€â”€TCP/gRPCâ”€â”€â–¶ Worker (registered in etcd)\n",
        "                     â”‚                              â”‚\n",
        "                     â””â”€â”€â”€â”€â”€â”€â”€â”€ etcd â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                              (service discovery)\n",
        "```\n",
        "\n",
        "**Key entries in etcd:**\n",
        "\n",
        "| Key Pattern | Purpose | Example Data |\n",
        "|-------------|---------|--------------|\n",
        "| `v1/instances/...` | Worker endpoint registration | `transport.tcp`: worker's address for direct communication |\n",
        "| `v1/mdc/...` | Model Card | Model configuration, context length, runtime settings |\n",
        "\n",
        "**How the Frontend finds Workers:**\n",
        "\n",
        "1. Worker starts â†’ registers itself in etcd with its TCP address\n",
        "2. Frontend queries etcd for `v1/instances/*` to discover available workers\n",
        "3. Frontend connects directly to worker via TCP (the address in `transport.tcp`)\n",
        "4. Inference requests flow over this direct TCP connection (not through etcd or NATS)\n",
        "\n",
        "**Role of each component:**\n",
        "\n",
        "| Component | Protocol | Purpose |\n",
        "|-----------|----------|---------|\n",
        "| **etcd** | HTTP :2379 | \"Who exists?\" - Service discovery, worker registration |\n",
        "| **NATS** | TCP :4222 | \"What's happening?\" - KV cache events, metrics (async) |\n",
        "| **Frontendâ†’Worker** | TCP/gRPC | Actual inference requests (low-latency direct connection) |\n",
        "\n",
        "> **Key insight**: NATS is used for event streaming (KV cache notifications), not for request/response. This keeps the inference hot path fast by avoiding message queue latency."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ðŸŽ‰ Congratulations!\n",
        "\n",
        "You now have a working Dynamo setup:\n",
        "\n",
        "| Component | Status | Port |\n",
        "|-----------|--------|------|\n",
        "| etcd (Service Discovery) | Running | 2379 |\n",
        "| NATS (Messaging) | Running | 4222 |\n",
        "| Dynamo Worker (SGLang) | Running | 8000 |\n",
        "\n",
        "### What's Next?\n",
        "\n",
        "- **Module 02**: Deep dive into the Frontend (HTTP handling, routing)\n",
        "- **Module 03**: Compare different backends (vLLM, SGLang, TensorRT-LLM)\n",
        "- **Module 04**: Understanding etcd service discovery in detail"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Cleanup (Optional)\n",
        "\n",
        "Run this cell to stop the Dynamo processes when you're done:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dynamo processes stopped\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "# Stop Dynamo processes\n",
        "pkill -f 'python -m dynamo' || true\n",
        "echo \"Dynamo processes stopped\"\n",
        "\n",
        "# Uncomment below to also stop infrastructure containers\n",
        "# docker stop dynamo-etcd dynamo-nats\n",
        "# docker rm dynamo-etcd dynamo-nats"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
