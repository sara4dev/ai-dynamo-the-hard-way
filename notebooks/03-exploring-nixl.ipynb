{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Module 03: Exploring NIXL (NVIDIA Inference Xfer Library)\n",
        "\n",
        "> **Goal**: Understand how NIXL enables fast GPU-to-GPU KV cache transfers in disaggregated serving.\n",
        "\n",
        "---\n",
        "\n",
        "## What is NIXL?\n",
        "\n",
        "**NIXL** (NVIDIA Inference Xfer Library) is a high-performance data transfer library designed for AI inference. It enables **direct GPU-to-GPU transfers** without CPU involvement using RDMA (Remote Direct Memory Access).\n",
        "\n",
        "### Why NIXL Matters for Disaggregated Serving\n",
        "\n",
        "In disaggregated LLM serving, prefill and decode run on separate GPUs. The KV cache must move between them:\n",
        "\n",
        "```\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚  Prefill Worker â”‚                    â”‚  Decode Worker  â”‚\n",
        "â”‚     (GPU 0)     â”‚                    â”‚     (GPU 1)     â”‚\n",
        "â”‚                 â”‚                    â”‚                 â”‚\n",
        "â”‚  KV Cache       â”‚â•â•â•â•â•â•â•NIXLâ•â•â•â•â•â•â•â•â–¶â”‚  KV Cache       â”‚\n",
        "â”‚  (VRAM)         â”‚   Direct Transfer  â”‚  (VRAM)         â”‚\n",
        "â”‚                 â”‚   ~10-50 GB/s      â”‚                 â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "```\n",
        "\n",
        "**Without NIXL**, you'd need: GPU 0 â†’ CPU RAM â†’ Network/IPC â†’ CPU RAM â†’ GPU 1\n",
        "\n",
        "**With NIXL**: GPU 0 â†’ GPU 1 (direct RDMA, bypasses CPU entirely)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Step 1: Install and Verify NIXL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2mUsing Python 3.12.3 environment at: /root/src/github.com/sara4dev/ai-dynamo-the-hard-way/.venv\u001b[0m\n",
            "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 23ms\u001b[0m\u001b[0m\n",
            "NIXL installed at: /root/src/github.com/sara4dev/ai-dynamo-the-hard-way/.venv/lib/python3.12/site-packages/nixl/__init__.py\n",
            "\u001b[2mUsing Python 3.12.3 environment at: /root/src/github.com/sara4dev/ai-dynamo-the-hard-way/.venv\u001b[0m\n",
            "Name: nixl\n",
            "Version: 0.8.0\n"
          ]
        }
      ],
      "source": [
        "# Install NIXL\n",
        "!uv pip install nixl\n",
        "\n",
        "import nixl\n",
        "print(f\"NIXL installed at: {nixl.__file__}\")\n",
        "!uv pip show nixl | grep -E \"^(Name|Version)\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Step 2: NIXL Core Concepts\n",
        "\n",
        "Before diving into the transfer demo, let's understand the key NIXL components.\n",
        "\n",
        "### Key Components\n",
        "\n",
        "| Component | Purpose |\n",
        "|-----------|--------|\n",
        "| **nixlAgent** | Core class - each process creates one to participate in transfers |\n",
        "| **Backend (UCX)** | Handles actual data movement via RDMA, NVLink, or TCP |\n",
        "| **Memory Registration** | Makes GPU memory accessible for RDMA operations |\n",
        "| **Metadata Exchange** | Allows agents to discover each other's registered memory |\n",
        "| **Transfer Requests** | Describes what data to move and where |\n",
        "\n",
        "### Memory Types\n",
        "\n",
        "| Type | Description |\n",
        "|------|-------------|\n",
        "| `VRAM_SEG` | GPU memory (what we'll use for KV cache) |\n",
        "| `DRAM_SEG` | CPU memory |\n",
        "| `FILE_SEG` | File storage |\n",
        "\n",
        "### Transfer Operations\n",
        "\n",
        "| Operation | Description |\n",
        "|-----------|-------------|\n",
        "| `NIXL_READ` | Pull data FROM remote agent |\n",
        "| `NIXL_WRITE` | Push data TO remote agent |\n",
        "\n",
        "### Key Status Codes\n",
        "\n",
        "| Status | Meaning |\n",
        "|--------|---------|\n",
        "| `NIXL_SUCCESS` | Operation completed |\n",
        "| `NIXL_IN_PROG` | Transfer in progress (async) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Step 3: Multi-Process GPU-to-GPU Transfer Demo\n",
        "\n",
        "Now let's perform an actual GPU-to-GPU transfer using NIXL with **separate processes** - exactly how Dynamo runs prefill and decode workers in production.\n",
        "\n",
        "### Architecture\n",
        "\n",
        "Run the cell below to see the sequence diagram:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<img src=\"https://mermaid.ink/img/CnNlcXVlbmNlRGlhZ3JhbQogICAgcGFydGljaXBhbnQgUCBhcyBQcmVmaWxsIChHUFUgMCkKICAgIHBhcnRpY2lwYW50IEUgYXMgZXRjZAogICAgcGFydGljaXBhbnQgRCBhcyBEZWNvZGUgKEdQVSAxKQoKICAgIE5vdGUgb3ZlciBQOiBDcmVhdGUgbml4bF9hZ2VudCAobGlzdGVuZXIpPGJyLz5BbGxvY2F0ZSBLViBjYWNoZTxici8-UmVnaXN0ZXIgbWVtb3J5IHdpdGggTklYTAogICAgTm90ZSBvdmVyIEQ6IENyZWF0ZSBuaXhsX2FnZW50PGJyLz5BbGxvY2F0ZSBkZXN0IGJ1ZmZlcjxici8-UmVnaXN0ZXIgbWVtb3J5IHdpdGggTklYTAoKICAgIFAtPj5FOiBSZWdpc3RlciBlbmRwb2ludCAoL25peGwve2lkfS9wcmVmaWxsX2VuZHBvaW50KQogICAgRC0-PkU6IFBvbGwgZm9yIHByZWZpbGwgZW5kcG9pbnQKICAgIEUtLT4-RDogUmV0dXJuIHByZWZpbGwgZW5kcG9pbnQKCiAgICBELT4-UDogQ29ubmVjdCB0byBwcmVmaWxsCiAgICBQLT4-RDogRXhjaGFuZ2UgTklYTCBtZXRhZGF0YQogICAgRC0-PlA6IEV4Y2hhbmdlIE5JWEwgbWV0YWRhdGEKICAgIFAtPj5EOiBTZW5kIHRyYW5zZmVyIGRlc2NyaXB0b3JzCgogICAgTm90ZSBvdmVyIEQ6IENyZWF0ZSBSRUFEIHRyYW5zZmVyCiAgICBQLS0-PkQ6IERBVEEgVFJBTlNGRVIgKEdQVSAwIOKGkiBHUFUgMSkKICAgIE5vdGUgb3ZlciBEOiBWZXJpZnkgZGF0YQoKICAgIEQtPj5FOiBTaWduYWwgZG9uZSAoL25peGwve2lkfS9kb25lKQogICAgRS0tPj5QOiBSZWNlaXZlIGRvbmUgc2lnbmFsCgogICAgTm90ZSBvdmVyIFAsRDogQ2xlYW51cAo=\" width=\"800\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Architecture diagram rendered (via mermaid.ink)\n"
          ]
        }
      ],
      "source": [
        "import base64\n",
        "import urllib.parse\n",
        "from IPython.display import display, Image, SVG\n",
        "\n",
        "# Mermaid diagram definition\n",
        "mermaid_code = \"\"\"\n",
        "sequenceDiagram\n",
        "    participant P as Prefill (GPU 0)\n",
        "    participant E as etcd\n",
        "    participant D as Decode (GPU 1)\n",
        "\n",
        "    Note over P: Create nixl_agent (listener)<br/>Allocate KV cache<br/>Register memory with NIXL\n",
        "    Note over D: Create nixl_agent<br/>Allocate dest buffer<br/>Register memory with NIXL\n",
        "    \n",
        "    P->>E: Register endpoint (/nixl/{id}/prefill_endpoint)\n",
        "    D->>E: Poll for prefill endpoint\n",
        "    E-->>D: Return prefill endpoint\n",
        "    \n",
        "    D->>P: Connect to prefill\n",
        "    P->>D: Exchange NIXL metadata\n",
        "    D->>P: Exchange NIXL metadata\n",
        "    P->>D: Send transfer descriptors\n",
        "    \n",
        "    Note over D: Create READ transfer\n",
        "    P-->>D: DATA TRANSFER (GPU 0 â†’ GPU 1)\n",
        "    Note over D: Verify data\n",
        "    \n",
        "    D->>E: Signal done (/nixl/{id}/done)\n",
        "    E-->>P: Receive done signal\n",
        "    \n",
        "    Note over P,D: Cleanup\n",
        "\"\"\"\n",
        "\n",
        "# Render using mermaid.ink service (generates SVG from mermaid code)\n",
        "encoded = base64.urlsafe_b64encode(mermaid_code.encode('utf-8')).decode('ascii')\n",
        "img_url = f\"https://mermaid.ink/img/{encoded}\"\n",
        "\n",
        "# Display the diagram\n",
        "display(Image(url=img_url, width=800))\n",
        "print(\"âœ“ Architecture diagram rendered (via mermaid.ink)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### How This Maps to Dynamo\n",
        "\n",
        "| This Demo | Dynamo Production |\n",
        "|-----------|-------------------|\n",
        "| etcd for endpoint discovery | etcd for service registry |\n",
        "| etcd for completion signal | NATS for request coordination |\n",
        "| NIXL for data transfer | NIXL for KV cache transfer |\n",
        "| Direct IP:port connection | Kubernetes service discovery |\n",
        "\n",
        "### Transport Selection\n",
        "\n",
        "UCX automatically selects the best available transport:\n",
        "\n",
        "| Transport | Used When | Bandwidth |\n",
        "|-----------|-----------|-----------|\n",
        "| NVLink | Same node, NVLink available | ~600 GB/s |\n",
        "| cuda_ipc | Same node, P2P enabled | ~25-50 GB/s |\n",
        "| RDMA | Cross-node, RDMA NIC | ~25-100 GB/s |\n",
        "| TCP (fallback) | No P2P, no RDMA | ~1-10 Gbps |\n",
        "\n",
        "> **Note**: Consumer GPUs (like RTX) often don't support P2P over PCIe. NIXL will automatically fall back to TCP + CPU staging. Datacenter GPUs (A100, H100) have NVLink and full RDMA support."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "NIXL + etcd MULTI-PROCESS GPU-TO-GPU TRANSFER\n",
            "======================================================================\n",
            "\n",
            "âœ“ Found 2 GPUs:\n",
            "   GPU 0: NVIDIA GeForce RTX 5090\n",
            "   GPU 1: NVIDIA GeForce RTX 5090\n",
            "\n",
            "âœ“ P2P Access Check:\n",
            "   GPU 0 â†’ GPU 1: False\n",
            "   GPU 1 â†’ GPU 0: False\n",
            "\n",
            "âš ï¸  P2P not available - NIXL will use TCP + CPU staging (slower)\n",
            "   This is normal for consumer GPUs (RTX series)\n",
            "   Datacenter GPUs (A100, H100) have NVLink with full P2P support\n",
            "\n",
            "âœ“ Connected to etcd at localhost:2379\n",
            "  Dynamo uses etcd for service discovery and coordination\n",
            "\n",
            "âœ“ Prefill worker will listen on port 15555\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import os\n",
        "import time\n",
        "\n",
        "# Install etcd client (using etcd3gw for protobuf compatibility)\n",
        "!uv pip install etcd3gw -q\n",
        "from etcd3gw import Etcd3Client\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"NIXL + etcd MULTI-PROCESS GPU-TO-GPU TRANSFER\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Verify we have 2 GPUs\n",
        "assert torch.cuda.device_count() >= 2, \"This demo requires 2 GPUs\"\n",
        "print(f\"\\nâœ“ Found {torch.cuda.device_count()} GPUs:\")\n",
        "for i in range(2):\n",
        "    print(f\"   GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
        "\n",
        "# Check P2P capability (affects which transport UCX will use)\n",
        "p2p_0_to_1 = torch.cuda.can_device_access_peer(0, 1)\n",
        "p2p_1_to_0 = torch.cuda.can_device_access_peer(1, 0)\n",
        "print(f\"\\nâœ“ P2P Access Check:\")\n",
        "print(f\"   GPU 0 â†’ GPU 1: {p2p_0_to_1}\")\n",
        "print(f\"   GPU 1 â†’ GPU 0: {p2p_1_to_0}\")\n",
        "\n",
        "if not (p2p_0_to_1 and p2p_1_to_0):\n",
        "    print(\"\\nâš ï¸  P2P not available - NIXL will use TCP + CPU staging (slower)\")\n",
        "    print(\"   This is normal for consumer GPUs (RTX series)\")\n",
        "    print(\"   Datacenter GPUs (A100, H100) have NVLink with full P2P support\")\n",
        "else:\n",
        "    print(\"\\nâœ“ P2P enabled - NIXL can use cuda_ipc for fast transfers\")\n",
        "\n",
        "# Connect to etcd (used for service discovery, like Dynamo)\n",
        "ETCD_HOST = os.environ.get(\"ETCD_HOST\", \"localhost\")\n",
        "ETCD_PORT = int(os.environ.get(\"ETCD_PORT\", 2379))\n",
        "try:\n",
        "    etcd_client = Etcd3Client(host=ETCD_HOST, port=ETCD_PORT)\n",
        "    etcd_client.status()\n",
        "    print(f\"\\nâœ“ Connected to etcd at {ETCD_HOST}:{ETCD_PORT}\")\n",
        "    print(\"  Dynamo uses etcd for service discovery and coordination\")\n",
        "except Exception as e:\n",
        "    raise RuntimeError(\n",
        "        f\"etcd not available at {ETCD_HOST}:{ETCD_PORT}. \"\n",
        "        \"Start with: docker run -d -p 2379:2379 quay.io/coreos/etcd:v3.5.0 \"\n",
        "        \"/usr/local/bin/etcd --listen-client-urls http://0.0.0.0:2379 \"\n",
        "        \"--advertise-client-urls http://0.0.0.0:2379\"\n",
        "    ) from e\n",
        "\n",
        "# Configuration for the demo\n",
        "PREFILL_PORT = 15555  # Port for prefill worker to listen on\n",
        "print(f\"\\nâœ“ Prefill worker will listen on port {PREFILL_PORT}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3.1: Define the Prefill Worker\n",
        "\n",
        "The prefill worker runs on GPU 0 as a **separate process**. It:\n",
        "1. Creates a NIXL agent with a **listener thread** (accepts connections)\n",
        "2. Allocates and registers KV cache memory on GPU 0\n",
        "3. **Registers its endpoint in etcd** (so decode can discover it)\n",
        "4. Waits for decode to connect and exchange NIXL metadata\n",
        "5. Sends transfer descriptors so decode knows the memory layout\n",
        "6. **Waits for completion signal in etcd**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Prefill worker function defined\n"
          ]
        }
      ],
      "source": [
        "def prefill_worker(request_id: str, etcd_host: str, etcd_port: int, nixl_port: int):\n",
        "    \"\"\"\n",
        "    Prefill Worker - runs in a separate process on GPU 0\n",
        "    \n",
        "    In production (Dynamo), this would be a separate container/pod\n",
        "    running on a prefill-optimized GPU instance.\n",
        "    \n",
        "    Uses etcd for:\n",
        "    - Service discovery (registers endpoint so decode can find us)\n",
        "    - Completion signaling (waits for decode to signal done)\n",
        "    \n",
        "    Uses NIXL for:\n",
        "    - Memory registration\n",
        "    - Metadata exchange\n",
        "    - Data transfer\n",
        "    \"\"\"\n",
        "    import os\n",
        "    import time\n",
        "    import torch\n",
        "    from etcd3gw import Etcd3Client\n",
        "    from nixl._api import nixl_agent, nixl_agent_config\n",
        "    \n",
        "    # etcd keys for this request (like Dynamo uses request IDs)\n",
        "    endpoint_key = f\"/nixl/{request_id}/prefill_endpoint\"\n",
        "    done_key = f\"/nixl/{request_id}/done\"\n",
        "    result_key = f\"/nixl/{request_id}/prefill_result\"\n",
        "    \n",
        "    print(f\"[PREFILL] Starting worker (PID: {os.getpid()}) on port {nixl_port}\")\n",
        "    \n",
        "    try:\n",
        "        etcd = Etcd3Client(host=etcd_host, port=etcd_port)\n",
        "        \n",
        "        # === STEP 1: Create NIXL agent with listener ===\n",
        "        config = nixl_agent_config(\n",
        "            enable_prog_thread=True,\n",
        "            enable_listen_thread=True,  # Accept incoming connections\n",
        "            listen_port=nixl_port,      # Listen on this port\n",
        "            backends=[\"UCX\"]\n",
        "        )\n",
        "        agent = nixl_agent(\"prefill-worker\", config)\n",
        "        print(f\"[PREFILL] Created agent, listening on port {nixl_port}\")\n",
        "        \n",
        "        # === STEP 2: Allocate KV cache on GPU 0 ===\n",
        "        # Use random data like production (not deterministic arange)\n",
        "        # Use a large buffer (1 GB) to properly measure TCP bandwidth\n",
        "        torch.cuda.set_device(0)\n",
        "        torch.manual_seed(42)  # For reproducibility in demo\n",
        "        kv_cache = torch.randn(16384, 32768, device='cuda:0', dtype=torch.float16)  # 1 GB\n",
        "        size_bytes = kv_cache.numel() * kv_cache.element_size()\n",
        "        size_gb = size_bytes / (1024 ** 3)\n",
        "        flat = kv_cache.flatten()\n",
        "        print(f\"[PREFILL] KV cache on GPU 0: {tuple(kv_cache.shape)}, {size_gb:.2f} GB\")\n",
        "        print(f\"[PREFILL] SOURCE tensor (first 5): [{flat[0]:.4f}, {flat[1]:.4f}, {flat[2]:.4f}, {flat[3]:.4f}, {flat[4]:.4f}]\")\n",
        "        print(f\"[PREFILL] SOURCE tensor (last 5):  [{flat[-5]:.4f}, {flat[-4]:.4f}, {flat[-3]:.4f}, {flat[-2]:.4f}, {flat[-1]:.4f}]\")\n",
        "        \n",
        "        # === STEP 3: Register memory with NIXL ===\n",
        "        reg_descs = agent.register_memory(kv_cache)\n",
        "        print(f\"[PREFILL] Memory registered with NIXL\")\n",
        "        \n",
        "        # Build transfer descriptors (decode will need this)\n",
        "        xfer_descs = agent.get_xfer_descs(kv_cache)\n",
        "        xfer_descs_serialized = agent.get_serialized_descs(xfer_descs)\n",
        "        \n",
        "        # === STEP 4: Register endpoint in etcd (service discovery) ===\n",
        "        # In Dynamo, workers register themselves so others can discover them\n",
        "        endpoint_info = f\"127.0.0.1:{nixl_port}\"\n",
        "        etcd.put(endpoint_key, endpoint_info)\n",
        "        print(f\"[PREFILL] Registered endpoint in etcd: {endpoint_key} = {endpoint_info}\")\n",
        "        print(f\"[PREFILL] Decode worker can now discover us via etcd\")\n",
        "        \n",
        "        # === STEP 5: Wait for decode to connect ===\n",
        "        print(f\"[PREFILL] Waiting for decode worker to connect...\")\n",
        "        while not agent.check_remote_metadata(\"decode-worker\"):\n",
        "            time.sleep(0.1)\n",
        "        print(f\"[PREFILL] Decode worker connected!\")\n",
        "        \n",
        "        # === STEP 6: Send transfer descriptors to decode ===\n",
        "        agent.send_notif(\"decode-worker\", xfer_descs_serialized)\n",
        "        print(f\"[PREFILL] Sent transfer descriptors to decode worker\")\n",
        "        \n",
        "        # === STEP 7: Wait for completion signal in etcd ===\n",
        "        print(f\"[PREFILL] Waiting for completion signal in etcd...\")\n",
        "        while True:\n",
        "            result = etcd.get(done_key)\n",
        "            if result and result[0]:\n",
        "                print(f\"[PREFILL] Received completion signal from etcd\")\n",
        "                break\n",
        "            time.sleep(0.1)\n",
        "        \n",
        "        # === STEP 8: Cleanup ===\n",
        "        agent.deregister_memory(reg_descs)\n",
        "        etcd.put(result_key, \"success\")\n",
        "        print(f\"[PREFILL] Cleanup complete\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        import traceback\n",
        "        print(f\"[PREFILL] Error: {e}\")\n",
        "        traceback.print_exc()\n",
        "        try:\n",
        "            etcd.put(result_key, f\"error: {e}\")\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "print(\"âœ“ Prefill worker function defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3.2: Define the Decode Worker\n",
        "\n",
        "The decode worker runs on GPU 1 as a **separate process**. It:\n",
        "1. **Discovers prefill's endpoint from etcd** (service discovery)\n",
        "2. Creates a NIXL agent and connects to prefill\n",
        "3. Allocates destination buffer on GPU 1\n",
        "4. Exchanges NIXL metadata with prefill\n",
        "5. Creates a `READ` transfer request to **pull** data from prefill\n",
        "6. Executes the transfer and verifies data integrity\n",
        "7. **Signals completion via etcd**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Decode worker function defined\n"
          ]
        }
      ],
      "source": [
        "def decode_worker(request_id: str, etcd_host: str, etcd_port: int):\n",
        "    \"\"\"\n",
        "    Decode Worker - runs in a separate process on GPU 1\n",
        "    \n",
        "    In production (Dynamo), this would be a separate container/pod\n",
        "    running on a decode-optimized GPU instance.\n",
        "    \n",
        "    Uses etcd for:\n",
        "    - Service discovery (finds prefill's endpoint)\n",
        "    - Completion signaling (notifies prefill when done)\n",
        "    \n",
        "    Uses NIXL for:\n",
        "    - Memory registration\n",
        "    - Metadata exchange\n",
        "    - Data transfer\n",
        "    \"\"\"\n",
        "    import os\n",
        "    import time\n",
        "    import torch\n",
        "    from etcd3gw import Etcd3Client\n",
        "    from nixl._api import nixl_agent, nixl_agent_config\n",
        "    \n",
        "    # etcd keys for this request\n",
        "    endpoint_key = f\"/nixl/{request_id}/prefill_endpoint\"\n",
        "    done_key = f\"/nixl/{request_id}/done\"\n",
        "    result_key = f\"/nixl/{request_id}/decode_result\"\n",
        "    \n",
        "    print(f\"[DECODE] Starting worker (PID: {os.getpid()})\")\n",
        "    \n",
        "    try:\n",
        "        etcd = Etcd3Client(host=etcd_host, port=etcd_port)\n",
        "        \n",
        "        # === STEP 1: Discover prefill endpoint from etcd ===\n",
        "        print(f\"[DECODE] Discovering prefill endpoint from etcd...\")\n",
        "        prefill_endpoint = None\n",
        "        for _ in range(60):  # Timeout after 60 seconds\n",
        "            result = etcd.get(endpoint_key)\n",
        "            if result and result[0]:\n",
        "                value = result[0]\n",
        "                prefill_endpoint = value.decode('utf-8') if isinstance(value, bytes) else value\n",
        "                break\n",
        "            time.sleep(1)\n",
        "        \n",
        "        if not prefill_endpoint:\n",
        "            raise TimeoutError(f\"Prefill endpoint not found in etcd at {endpoint_key}\")\n",
        "        \n",
        "        prefill_ip, prefill_port = prefill_endpoint.split(\":\")\n",
        "        prefill_port = int(prefill_port)\n",
        "        print(f\"[DECODE] Found prefill at {prefill_ip}:{prefill_port} (from etcd)\")\n",
        "        \n",
        "        # === STEP 2: Create NIXL agent ===\n",
        "        config = nixl_agent_config(\n",
        "            enable_prog_thread=True,\n",
        "            enable_listen_thread=True,\n",
        "            listen_port=0,  # Use any available port\n",
        "            backends=[\"UCX\"]\n",
        "        )\n",
        "        agent = nixl_agent(\"decode-worker\", config)\n",
        "        print(f\"[DECODE] Agent created\")\n",
        "        \n",
        "        # === STEP 3: Allocate destination buffer on GPU 1 ===\n",
        "        # Match prefill size (1 GB)\n",
        "        torch.cuda.set_device(1)\n",
        "        dest_buffer = torch.zeros(16384, 32768, device='cuda:1', dtype=torch.float16)  # 1 GB\n",
        "        size_bytes = dest_buffer.numel() * dest_buffer.element_size()\n",
        "        size_gb = size_bytes / (1024 ** 3)\n",
        "        flat = dest_buffer.flatten()\n",
        "        print(f\"[DECODE] Dest buffer on GPU 1: {tuple(dest_buffer.shape)}, {size_gb:.2f} GB\")\n",
        "        print(f\"[DECODE] BEFORE transfer (first 5): [{flat[0]:.4f}, {flat[1]:.4f}, {flat[2]:.4f}, {flat[3]:.4f}, {flat[4]:.4f}]\")\n",
        "        print(f\"[DECODE] BEFORE transfer (last 5):  [{flat[-5]:.4f}, {flat[-4]:.4f}, {flat[-3]:.4f}, {flat[-2]:.4f}, {flat[-1]:.4f}]\")\n",
        "        \n",
        "        # === STEP 4: Register local memory ===\n",
        "        reg_descs = agent.register_memory(dest_buffer)\n",
        "        print(f\"[DECODE] Memory registered with NIXL\")\n",
        "        \n",
        "        # === STEP 5: Exchange NIXL metadata with prefill ===\n",
        "        agent.send_local_metadata(prefill_ip, prefill_port)\n",
        "        agent.fetch_remote_metadata(\"prefill-worker\", prefill_ip, prefill_port)\n",
        "        print(f\"[DECODE] NIXL metadata exchange initiated\")\n",
        "        \n",
        "        while not agent.check_remote_metadata(\"prefill-worker\"):\n",
        "            time.sleep(0.1)\n",
        "        print(f\"[DECODE] Have prefill's NIXL metadata\")\n",
        "        \n",
        "        # === STEP 6: Receive transfer descriptors from prefill ===\n",
        "        remote_descs = None\n",
        "        while remote_descs is None:\n",
        "            notifs = agent.get_new_notifs()\n",
        "            if \"prefill-worker\" in notifs and notifs[\"prefill-worker\"]:\n",
        "                remote_descs = agent.deserialize_descs(notifs[\"prefill-worker\"][0])\n",
        "                break\n",
        "            time.sleep(0.1)\n",
        "        print(f\"[DECODE] Received prefill's transfer descriptors\")\n",
        "        \n",
        "        local_descs = agent.get_xfer_descs(dest_buffer)\n",
        "        \n",
        "        # === STEP 7: Create transfer request ===\n",
        "        print(f\"[DECODE] Creating READ transfer request...\")\n",
        "        xfer_handle = agent.initialize_xfer(\n",
        "            \"READ\",           # Pull from remote\n",
        "            local_descs,      # Where to put data (GPU 1)\n",
        "            remote_descs,     # Where to get data (GPU 0)\n",
        "            \"prefill-worker\"  # Remote agent name\n",
        "        )\n",
        "        print(f\"[DECODE] Transfer request created\")\n",
        "        \n",
        "        # === STEP 8: Execute the transfer ===\n",
        "        print(f\"[DECODE] Executing transfer GPU 0 â†’ GPU 1...\")\n",
        "        start_time = time.perf_counter()\n",
        "        \n",
        "        status = agent.transfer(xfer_handle)\n",
        "        print(f\"[DECODE] Transfer posted, status: {status}\")\n",
        "        \n",
        "        while True:\n",
        "            state = agent.check_xfer_state(xfer_handle)\n",
        "            if state == \"DONE\":\n",
        "                break\n",
        "            elif state == \"ERR\":\n",
        "                raise RuntimeError(\"Transfer failed\")\n",
        "            time.sleep(0.001)\n",
        "        \n",
        "        elapsed = time.perf_counter() - start_time\n",
        "        bandwidth_gbps = (size_bytes * 8 / 1e9) / elapsed  # Gbps (network convention)\n",
        "        bandwidth_gbs = (size_bytes / (1024 ** 3)) / elapsed  # GB/s (for reference)\n",
        "        \n",
        "        print(f\"[DECODE] Transfer complete!\")\n",
        "        print(f\"          Size: {size_gb:.2f} GB\")\n",
        "        print(f\"          Time: {elapsed * 1000:.1f} ms\")\n",
        "        print(f\"          Bandwidth: {bandwidth_gbps:.2f} Gbps ({bandwidth_gbs:.2f} GB/s)\")\n",
        "        \n",
        "        # === STEP 9: Print received data for manual inspection ===\n",
        "        torch.cuda.synchronize(1)\n",
        "        received = dest_buffer.flatten()\n",
        "        \n",
        "        print(f\"[DECODE] AFTER transfer (first 5):  [{received[0]:.4f}, {received[1]:.4f}, {received[2]:.4f}, {received[3]:.4f}, {received[4]:.4f}]\")\n",
        "        print(f\"[DECODE] AFTER transfer (last 5):   [{received[-5]:.4f}, {received[-4]:.4f}, {received[-3]:.4f}, {received[-2]:.4f}, {received[-1]:.4f}]\")\n",
        "        print(f\"[DECODE] âœ“ Transfer complete - compare with PREFILL SOURCE values above to verify!\")\n",
        "        etcd.put(result_key, \"success\")\n",
        "        \n",
        "        # === STEP 10: Signal completion via etcd ===\n",
        "        etcd.put(done_key, \"true\")\n",
        "        print(f\"[DECODE] Signaled completion via etcd\")\n",
        "        \n",
        "        # === STEP 11: Cleanup ===\n",
        "        agent.release_xfer_handle(xfer_handle)\n",
        "        agent.remove_remote_agent(\"prefill-worker\")\n",
        "        agent.deregister_memory(reg_descs)\n",
        "        print(f\"[DECODE] Cleanup complete\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        import traceback\n",
        "        print(f\"[DECODE] Error: {e}\")\n",
        "        traceback.print_exc()\n",
        "        try:\n",
        "            etcd.put(result_key, f\"error: {e}\")\n",
        "            etcd.put(done_key, \"true\")  # Signal done so prefill doesn't hang\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "print(\"âœ“ Decode worker function defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3.3: Run the Multi-Process Transfer\n",
        "\n",
        "Now we spawn both workers as separate processes and watch them communicate via NIXL + etcd.\n",
        "\n",
        "**Key points:**\n",
        "- Each worker runs in its own **separate process** (different PID)\n",
        "- Prefill registers its endpoint in **etcd** (service discovery)\n",
        "- Decode discovers prefill via **etcd**, then connects directly\n",
        "- NIXL metadata is exchanged via **direct network connection**\n",
        "- Data transfer uses **UCX** (with best available transport)\n",
        "- Completion is signaled via **etcd** (like NATS in Dynamo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "EXECUTING MULTI-PROCESS TRANSFER\n",
            "======================================================================\n",
            "\n",
            "ğŸ“¦ Request ID: ca751042\n",
            "\n",
            "   etcd keys that will be used:\n",
            "     /nixl/ca751042/prefill_endpoint  - Service discovery\n",
            "     /nixl/ca751042/done              - Completion signal\n",
            "     /nixl/ca751042/prefill_result    - Prefill status\n",
            "     /nixl/ca751042/decode_result     - Decode status\n",
            "\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Starting worker processes...\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "[PREFILL] Starting worker (PID: 2969385) on port 15555\n",
            "[DECODE] Starting worker (PID: 2969386)\n",
            "[DECODE] Discovering prefill endpoint from etcd...\n",
            "2026-02-01 22:40:44 NIXL INFO    _api.py:363 Backend UCX was instantiated\n",
            "2026-02-01 22:40:44 NIXL INFO    _api.py:253 Initialized NIXL agent: prefill-worker\n",
            "[PREFILL] Created agent, listening on port 15555\n",
            "[PREFILL] KV cache on GPU 0: (16384, 32768), 1.00 GB\n",
            "[PREFILL] SOURCE tensor (first 5): [0.1940, 2.1621, -0.1720, 0.8491, -1.9248]\n",
            "[PREFILL] SOURCE tensor (last 5):  [0.7773, -0.4097, -1.2119, -0.0996, 0.9058]\n",
            "[PREFILL] Memory registered with NIXL\n",
            "[PREFILL] Registered endpoint in etcd: /nixl/ca751042/prefill_endpoint = 127.0.0.1:15555\n",
            "[PREFILL] Decode worker can now discover us via etcd\n",
            "[PREFILL] Waiting for decode worker to connect...\n",
            "[DECODE] Found prefill at 127.0.0.1:15555 (from etcd)\n",
            "2026-02-01 22:40:46 NIXL INFO    _api.py:363 Backend UCX was instantiated\n",
            "2026-02-01 22:40:46 NIXL INFO    _api.py:253 Initialized NIXL agent: decode-worker\n",
            "[DECODE] Agent created\n",
            "[DECODE] Dest buffer on GPU 1: (16384, 32768), 1.00 GB\n",
            "[DECODE] BEFORE transfer (first 5): [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]\n",
            "[DECODE] BEFORE transfer (last 5):  [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]\n",
            "[DECODE] Memory registered with NIXL\n",
            "[DECODE] NIXL metadata exchange initiated\n",
            "[PREFILL] Decode worker connected!\n",
            "[PREFILL] Sent transfer descriptors to decode worker\n",
            "[PREFILL] Waiting for completion signal in etcd...\n",
            "[DECODE] Have prefill's NIXL metadata\n",
            "[DECODE] Received prefill's transfer descriptors\n",
            "[DECODE] Creating READ transfer request...\n",
            "[DECODE] Transfer request created\n",
            "[DECODE] Executing transfer GPU 0 â†’ GPU 1...\n",
            "[DECODE] Transfer posted, status: PROC\n",
            "[DECODE] Transfer complete!\n",
            "          Size: 1.00 GB\n",
            "          Time: 6068.6 ms\n",
            "          Bandwidth: 1.42 Gbps (0.16 GB/s)\n",
            "[DECODE] AFTER transfer (first 5):  [0.1940, 2.1621, -0.1720, 0.8491, -1.9248]\n",
            "[DECODE] AFTER transfer (last 5):   [0.7773, -0.4097, -1.2119, -0.0996, 0.9058]\n",
            "[DECODE] âœ“ Transfer complete - compare with PREFILL SOURCE values above to verify!\n",
            "[DECODE] Signaled completion via etcd\n",
            "[DECODE] Cleanup complete\n",
            "[PREFILL] Received completion signal from etcd\n",
            "[PREFILL] Cleanup complete\n",
            "\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Results (from etcd):\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "  Prefill: success\n",
            "  Decode:  success\n",
            "\n",
            "ğŸ‰ SUCCESS! Multi-process GPU-to-GPU transfer completed!\n",
            "\n",
            "What happened:\n",
            "  1. Prefill registered its endpoint in etcd (service discovery)\n",
            "  2. Decode discovered prefill via etcd\n",
            "  3. They connected directly and exchanged NIXL metadata\n",
            "  4. Decode pulled the KV cache from GPU 0 to GPU 1\n",
            "  5. Decode signaled completion via etcd\n",
            "\n",
            "This is exactly how Dynamo coordinates workers!\n",
            "\n",
            "======================================================================\n",
            "DEMO COMPLETE\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "import uuid\n",
        "\n",
        "# Use 'multiprocess' instead of 'multiprocessing' - it uses dill instead of pickle\n",
        "# and can serialize functions defined in notebooks. Drop-in replacement.\n",
        "!uv pip install multiprocess -q\n",
        "import multiprocess as mp\n",
        "\n",
        "# Set multiprocessing start method for CUDA compatibility\n",
        "try:\n",
        "    mp.set_start_method('spawn', force=True)\n",
        "except RuntimeError:\n",
        "    pass  # Already set\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"EXECUTING MULTI-PROCESS TRANSFER\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Create unique request ID (like Dynamo uses for each inference request)\n",
        "request_id = str(uuid.uuid4())[:8]\n",
        "print(f\"\\nğŸ“¦ Request ID: {request_id}\")\n",
        "print(f\"\\n   etcd keys that will be used:\")\n",
        "print(f\"     /nixl/{request_id}/prefill_endpoint  - Service discovery\")\n",
        "print(f\"     /nixl/{request_id}/done              - Completion signal\")\n",
        "print(f\"     /nixl/{request_id}/prefill_result    - Prefill status\")\n",
        "print(f\"     /nixl/{request_id}/decode_result     - Decode status\")\n",
        "print()\n",
        "\n",
        "prefill_proc = None\n",
        "decode_proc = None\n",
        "\n",
        "try:\n",
        "    # Spawn worker processes\n",
        "    prefill_proc = mp.Process(\n",
        "        target=prefill_worker,\n",
        "        args=(request_id, ETCD_HOST, ETCD_PORT, PREFILL_PORT)\n",
        "    )\n",
        "    decode_proc = mp.Process(\n",
        "        target=decode_worker,\n",
        "        args=(request_id, ETCD_HOST, ETCD_PORT)\n",
        "    )\n",
        "    \n",
        "    print(\"â”€\" * 70)\n",
        "    print(\"Starting worker processes...\")\n",
        "    print(\"â”€\" * 70)\n",
        "    \n",
        "    # Start both processes\n",
        "    prefill_proc.start()\n",
        "    decode_proc.start()\n",
        "    \n",
        "    # Wait for completion (timeout after 60 seconds)\n",
        "    prefill_proc.join(timeout=60)\n",
        "    decode_proc.join(timeout=60)\n",
        "    \n",
        "    print()\n",
        "    print(\"â”€\" * 70)\n",
        "    print(\"Results (from etcd):\")\n",
        "    print(\"â”€\" * 70)\n",
        "    \n",
        "    # Collect results from etcd\n",
        "    def get_etcd_value(key):\n",
        "        result = etcd_client.get(key)\n",
        "        if result and result[0]:\n",
        "            value = result[0]\n",
        "            return value.decode('utf-8') if isinstance(value, bytes) else value\n",
        "        return \"not reported\"\n",
        "    \n",
        "    prefill_status = get_etcd_value(f\"/nixl/{request_id}/prefill_result\")\n",
        "    decode_status = get_etcd_value(f\"/nixl/{request_id}/decode_result\")\n",
        "    \n",
        "    print(f\"  Prefill: {prefill_status}\")\n",
        "    print(f\"  Decode:  {decode_status}\")\n",
        "    \n",
        "    if prefill_status == \"success\" and decode_status == \"success\":\n",
        "        print()\n",
        "        print(\"ğŸ‰ SUCCESS! Multi-process GPU-to-GPU transfer completed!\")\n",
        "        print()\n",
        "        print(\"What happened:\")\n",
        "        print(\"  1. Prefill registered its endpoint in etcd (service discovery)\")\n",
        "        print(\"  2. Decode discovered prefill via etcd\")\n",
        "        print(\"  3. They connected directly and exchanged NIXL metadata\")\n",
        "        print(\"  4. Decode pulled the KV cache from GPU 0 to GPU 1\")\n",
        "        print(\"  5. Decode signaled completion via etcd\")\n",
        "        print()\n",
        "        print(\"This is exactly how Dynamo coordinates workers!\")\n",
        "    else:\n",
        "        print()\n",
        "        print(\"âš ï¸ Some workers reported issues - check output above\")\n",
        "\n",
        "finally:\n",
        "    # Cleanup etcd keys\n",
        "    for suffix in [\"/prefill_endpoint\", \"/done\", \"/prefill_result\", \"/decode_result\"]:\n",
        "        try:\n",
        "            etcd_client.delete(f\"/nixl/{request_id}{suffix}\")\n",
        "        except:\n",
        "            pass\n",
        "    \n",
        "    # Terminate any hanging processes\n",
        "    if prefill_proc and prefill_proc.is_alive():\n",
        "        prefill_proc.terminate()\n",
        "    if decode_proc and decode_proc.is_alive():\n",
        "        decode_proc.terminate()\n",
        "\n",
        "print()\n",
        "print(\"=\" * 70)\n",
        "print(\"DEMO COMPLETE\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Step 4: How This Maps to Dynamo\n",
        "\n",
        "Here's how our demo maps to real-world disaggregated LLM inference in Dynamo:\n",
        "\n",
        "| Demo Component | Dynamo Equivalent |\n",
        "|----------------|-------------------|\n",
        "| `prefill_worker()` | Prefill Worker container |\n",
        "| `decode_worker()` | Decode Worker container |\n",
        "| etcd endpoint registration | etcd service registry |\n",
        "| etcd endpoint discovery | Kubernetes / etcd service discovery |\n",
        "| etcd completion signal | NATS request coordination |\n",
        "| `nixl_agent` | NIXL agent in each worker |\n",
        "| `send_local_metadata()` | Direct NIXL metadata exchange |\n",
        "| `initialize_xfer(\"READ\", ...)` | KV cache transfer request |\n",
        "| UCX backend | RDMA/NVLink for fast transfers |\n",
        "\n",
        "### Dynamo Integration\n",
        "\n",
        "In Dynamo, NIXL is enabled with:\n",
        "```bash\n",
        "dynamo run ... --disaggregation-transfer-backend nixl\n",
        "```\n",
        "\n",
        "Dynamo handles all the agent creation, metadata exchange, and transfer coordination automatically.\n",
        "\n",
        "### Production Pattern (Simplified)\n",
        "\n",
        "```python\n",
        "# Prefill worker (after generating KV cache)\n",
        "from nixl._api import nixl_agent, nixl_agent_config\n",
        "\n",
        "agent = nixl_agent(\"prefill\", nixl_agent_config(enable_listen_thread=True, listen_port=5555))\n",
        "reg = agent.register_memory(kv_cache)\n",
        "# Register endpoint in etcd for service discovery\n",
        "etcd.put(f\"/workers/prefill/{worker_id}\", f\"{ip}:5555\")\n",
        "\n",
        "# Decode worker (before starting decode)\n",
        "# Discover prefill via etcd\n",
        "prefill_endpoint = etcd.get(f\"/workers/prefill/{target_worker}\")\n",
        "prefill_ip, prefill_port = prefill_endpoint.split(\":\")\n",
        "\n",
        "agent = nixl_agent(\"decode\", nixl_agent_config())\n",
        "agent.fetch_remote_metadata(\"prefill\", prefill_ip, int(prefill_port))\n",
        "xfer = agent.initialize_xfer(\"READ\", local_descs, remote_descs, \"prefill\")\n",
        "agent.transfer(xfer)\n",
        "# ... poll check_xfer_state() until \"DONE\", then use KV cache\n",
        "```\n",
        "\n",
        "### Transport Selection on Production Hardware\n",
        "\n",
        "| Hardware | Transport | Bandwidth |\n",
        "|----------|-----------|-----------|\n",
        "| DGX/HGX with NVLink | NVLink via UCX | 600+ GB/s |\n",
        "| Cross-node with RDMA NIC | RDMA via UCX | 25-100 GB/s |\n",
        "| Consumer GPUs (RTX) | TCP + CPU staging | 1-10 Gbps |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Key Takeaways\n",
        "\n",
        "1. **NIXL + etcd** - Dynamo uses etcd for service discovery and NIXL for high-performance data transfers\n",
        "\n",
        "2. **Service discovery** - Workers register endpoints in etcd so others can find them\n",
        "\n",
        "3. **`nixl_agent`** is the core class - each worker creates one to participate in transfers\n",
        "\n",
        "4. **Listener threads** (`enable_listen_thread=True`) allow agents to accept incoming connections\n",
        "\n",
        "5. **Network-based connections** - agents connect via IP:port discovered from etcd\n",
        "\n",
        "6. **UCX backend** automatically selects the best transport (NVLink > cuda_ipc > RDMA > TCP)\n",
        "\n",
        "7. **Memory registration** is required before transfers (enables RDMA/DMA mappings)\n",
        "\n",
        "8. **Pull model** - receivers create `READ` transfer requests to pull data from senders\n",
        "\n",
        "9. **Async execution** - `transfer()` is non-blocking, poll with `check_xfer_state()`\n",
        "\n",
        "10. **Fallback support** - on systems without P2P/NVLink, NIXL falls back to TCP + CPU staging\n",
        "\n",
        "---\n",
        "\n",
        "### Resources\n",
        "\n",
        "| Resource | URL |\n",
        "|----------|-----|\n",
        "| NIXL GitHub | https://github.com/ai-dynamo/nixl |\n",
        "| NIXL Docs | https://github.com/ai-dynamo/nixl/blob/main/docs/nixl.md |\n",
        "| NIXL Python API | https://github.com/ai-dynamo/nixl/blob/main/docs/python_api.md |\n",
        "| vLLM NIXL Guide | https://docs.vllm.ai/en/stable/features/nixl_connector_usage/ |"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
