{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 03: Exploring NIXL (NVIDIA Inference Xfer Library)\n",
    "\n",
    "> **Goal**: Understand how NIXL enables fast GPU-to-GPU KV cache transfers in disaggregated serving.\n",
    "\n",
    "---\n",
    "\n",
    "## What is NIXL?\n",
    "\n",
    "**NIXL** (NVIDIA Inference Xfer Library) is a high-performance data transfer library designed for AI inference. It provides:\n",
    "\n",
    "- **Direct GPU-to-GPU transfers** via RDMA (Remote Direct Memory Access)\n",
    "- **Unified API** across different memory types (GPU, CPU, storage)\n",
    "- **Modular backends** (UCX, GDS, etc.)\n",
    "\n",
    "### Why NIXL Matters for Disaggregated Serving\n",
    "\n",
    "In Module 02, we saw prefill and decode workers on separate GPUs. The KV cache must move between them:\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  Prefill Worker â”‚                    â”‚  Decode Worker  â”‚\n",
    "â”‚     (GPU 0)     â”‚                    â”‚     (GPU 1)     â”‚\n",
    "â”‚                 â”‚                    â”‚                 â”‚\n",
    "â”‚  KV Cache       â”‚â•â•â•â•â•â•â•NIXLâ•â•â•â•â•â•â•â•â–¶â”‚  KV Cache       â”‚\n",
    "â”‚  (VRAM)         â”‚   Direct Transfer  â”‚  (VRAM)         â”‚\n",
    "â”‚                 â”‚   ~10-50 GB/s      â”‚                 â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "Without NIXL, you'd need to:\n",
    "1. Copy KV cache from GPU 0 â†’ CPU RAM\n",
    "2. Send over network/IPC\n",
    "3. Copy from CPU RAM â†’ GPU 1\n",
    "\n",
    "NIXL bypasses the CPU entirely using RDMA, achieving much higher throughput.\n",
    "\n",
    "### NIXL Architecture\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                      Application Layer                       â”‚\n",
    "â”‚                    (Dynamo, vLLM, etc.)                      â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                        NIXL API                              â”‚\n",
    "â”‚         nixlAgent, registerMem, createXferReq, etc.         â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                    Backend Plugins                           â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚\n",
    "â”‚  â”‚   UCX   â”‚  â”‚   GDS   â”‚  â”‚  POSIX  â”‚  â”‚  Object Store   â”‚ â”‚\n",
    "â”‚  â”‚ (RDMA)  â”‚  â”‚ (NVMe)  â”‚  â”‚ (Files) â”‚  â”‚    (S3/GCS)     â”‚ â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                    Memory Segments                           â”‚\n",
    "â”‚        VRAM_SEG (GPU)  |  DRAM_SEG (CPU)  |  FILE_SEG       â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 1: Install and Import NIXL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install NIXL if not already installed\n",
    "!uv pip install nixl\n",
    "\n",
    "import nixl\n",
    "print(f\"NIXL installed at: {nixl.__file__}\")\n",
    "print(f\"\\nNIXL version info:\")\n",
    "!uv pip show nixl | grep -E \"^(Name|Version|Summary)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 2: Explore NIXL API\n",
    "\n",
    "Let's look at the main components of NIXL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nixl\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"NIXL API OVERVIEW\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Memory segment types\n",
    "print(\"\\nğŸ“¦ Memory Segment Types:\")\n",
    "segments = ['VRAM_SEG', 'DRAM_SEG', 'FILE_SEG', 'BLK_SEG', 'OBJ_SEG']\n",
    "for seg in segments:\n",
    "    if hasattr(nixl, seg):\n",
    "        val = getattr(nixl, seg)\n",
    "        desc = {\n",
    "            'VRAM_SEG': 'GPU memory (CUDA)',\n",
    "            'DRAM_SEG': 'CPU memory (RAM)',\n",
    "            'FILE_SEG': 'File-based storage',\n",
    "            'BLK_SEG': 'Block storage',\n",
    "            'OBJ_SEG': 'Object storage (S3, GCS)'\n",
    "        }.get(seg, '')\n",
    "        print(f\"  {seg} = {val}  # {desc}\")\n",
    "\n",
    "# Transfer operations\n",
    "print(\"\\nğŸ”„ Transfer Operations:\")\n",
    "print(f\"  NIXL_READ  = {nixl.NIXL_READ}   # Pull data from remote\")\n",
    "print(f\"  NIXL_WRITE = {nixl.NIXL_WRITE}  # Push data to remote\")\n",
    "\n",
    "# Status codes\n",
    "print(\"\\nâœ“ Status Codes:\")\n",
    "status_codes = ['NIXL_SUCCESS', 'NIXL_IN_PROG', 'NIXL_ERR_NOT_FOUND', 'NIXL_ERR_BACKEND']\n",
    "for code in status_codes:\n",
    "    if hasattr(nixl, code):\n",
    "        print(f\"  {code} = {getattr(nixl, code)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: Understand the nixlAgent\n",
    "\n",
    "The `nixlAgent` is the core class in NIXL. Each process that wants to transfer data creates an agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nixl import nixlAgent, nixlAgentConfig\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"nixlAgent - CORE TRANSFER CLASS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Show agent methods\n",
    "agent_methods = [m for m in dir(nixlAgent) if not m.startswith('_')]\n",
    "print(f\"\\nAgent has {len(agent_methods)} methods:\\n\")\n",
    "\n",
    "# Group by function\n",
    "method_groups = {\n",
    "    'Memory': ['registerMem', 'deregisterMem', 'queryMem'],\n",
    "    'Transfer': ['createXferReq', 'makeXferReq', 'postXferReq', 'releaseXferReq'],\n",
    "    'Status': ['getXferStatus', 'getXferTelemetry', 'estimateXferCost'],\n",
    "    'Metadata': ['getLocalMD', 'fetchRemoteMD', 'loadRemoteMD', 'sendLocalMD'],\n",
    "    'Notification': ['genNotif', 'getNotifs'],\n",
    "    'Backend': ['createBackend', 'getAvailPlugins', 'getBackendParams'],\n",
    "    'Connection': ['makeConnection', 'checkRemoteMD'],\n",
    "}\n",
    "\n",
    "for group, methods in method_groups.items():\n",
    "    print(f\"ğŸ“Œ {group}:\")\n",
    "    for m in methods:\n",
    "        if m in agent_methods:\n",
    "            print(f\"     â€¢ {m}()\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 4: Create a NIXL Agent\n",
    "\n",
    "Let's create an agent and explore its capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nixl import nixlAgent, nixlAgentConfig\n",
    "import uuid\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CREATING A NIXL AGENT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create agent configuration\n",
    "config = nixlAgentConfig()\n",
    "agent_name = f\"notebook-agent-{uuid.uuid4().hex[:8]}\"\n",
    "\n",
    "# Create the agent\n",
    "agent = nixlAgent(agent_name, config)\n",
    "print(f\"\\nâœ“ Created agent: {agent_name}\")\n",
    "\n",
    "# Check available plugins/backends\n",
    "plugins = agent.getAvailPlugins()\n",
    "print(f\"\\nğŸ“¦ Available backends/plugins:\")\n",
    "for plugin in plugins:\n",
    "    print(f\"   â€¢ {plugin}\")\n",
    "    try:\n",
    "        params, required = agent.getPluginParams(plugin)\n",
    "        if params:\n",
    "            print(f\"     Parameters: {params}\")\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 5: Create a UCX Backend\n",
    "\n",
    "UCX (Unified Communication X) is the primary backend for GPU-to-GPU transfers. It supports:\n",
    "- **RDMA** (InfiniBand, RoCE)\n",
    "- **Shared memory** (same node)\n",
    "- **TCP** (fallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"CREATING UCX BACKEND\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create UCX backend with default options\n",
    "ucx_options = {}  # Use defaults\n",
    "\n",
    "try:\n",
    "    backend_handle = agent.createBackend(\"UCX\", ucx_options)\n",
    "    print(f\"\\nâœ“ UCX backend created, handle: {backend_handle}\")\n",
    "    \n",
    "    # Get backend parameters\n",
    "    params, supported = agent.getBackendParams(backend_handle)\n",
    "    print(f\"\\nğŸ“‹ UCX Backend Configuration:\")\n",
    "    for key, value in params.items():\n",
    "        print(f\"   {key}: {value}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\nâš ï¸  Could not create UCX backend: {e}\")\n",
    "    print(\"   This may require specific UCX libraries or RDMA hardware.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 6: Register GPU Memory\n",
    "\n",
    "Before transferring data, memory regions must be registered with NIXL. This allows the backend to set up RDMA mappings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from nixl import VRAM_SEG, DRAM_SEG\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"REGISTERING GPU MEMORY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Allocate some GPU memory (simulating a KV cache)\n",
    "if torch.cuda.is_available():\n",
    "    # Create a tensor on GPU (like a KV cache layer)\n",
    "    kv_cache_size = (32, 128, 64)  # (batch, seq_len, hidden_dim)\n",
    "    gpu_tensor = torch.randn(kv_cache_size, device='cuda:0', dtype=torch.float16)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Created GPU tensor:\")\n",
    "    print(f\"   Shape: {gpu_tensor.shape}\")\n",
    "    print(f\"   Size: {gpu_tensor.numel() * 2 / 1024:.2f} KB\")  # float16 = 2 bytes\n",
    "    print(f\"   Device: {gpu_tensor.device}\")\n",
    "    print(f\"   Data ptr: {hex(gpu_tensor.data_ptr())}\")\n",
    "    \n",
    "    # Create a descriptor list for registration\n",
    "    # Note: This shows the concept - actual registration requires proper setup\n",
    "    print(f\"\\nğŸ“ Memory Registration Concept:\")\n",
    "    print(f\"   1. Get tensor data pointer: {hex(gpu_tensor.data_ptr())}\")\n",
    "    print(f\"   2. Calculate size in bytes: {gpu_tensor.numel() * gpu_tensor.element_size()}\")\n",
    "    print(f\"   3. Specify segment type: VRAM_SEG = {VRAM_SEG}\")\n",
    "    print(f\"   4. Register with backend for RDMA access\")\n",
    "else:\n",
    "    print(\"âš ï¸  No GPU available for memory registration demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 7: Understanding the Transfer Flow\n",
    "\n",
    "Here's how a KV cache transfer works in disaggregated serving:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"NIXL TRANSFER FLOW\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "flow = \"\"\"\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    NIXL KV Cache Transfer                        â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                  â”‚\n",
    "â”‚  PREFILL WORKER (GPU 0)              DECODE WORKER (GPU 1)       â”‚\n",
    "â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•     â”‚\n",
    "â”‚                                                                  â”‚\n",
    "â”‚  1. Create nixlAgent                 1. Create nixlAgent         â”‚\n",
    "â”‚     agent_p = nixlAgent(...)            agent_d = nixlAgent(...) â”‚\n",
    "â”‚                                                                  â”‚\n",
    "â”‚  2. Create UCX backend               2. Create UCX backend       â”‚\n",
    "â”‚     backend = createBackend(\"UCX\")      backend = createBackend()â”‚\n",
    "â”‚                                                                  â”‚\n",
    "â”‚  3. Register KV cache memory         3. Register KV cache memory â”‚\n",
    "â”‚     registerMem(kv_cache_ptr)           registerMem(kv_cache_ptr)â”‚\n",
    "â”‚                                                                  â”‚\n",
    "â”‚  4. Export metadata â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶  4. Fetch remote metadata    â”‚\n",
    "â”‚     md = getLocalMD()                   fetchRemoteMD(agent_p)   â”‚\n",
    "â”‚     sendLocalMD()                                                â”‚\n",
    "â”‚                                                                  â”‚\n",
    "â”‚  5. (After prefill completes)        5. Create transfer request  â”‚\n",
    "â”‚     Generate KV cache data              req = createXferReq(     â”‚\n",
    "â”‚                                           NIXL_READ,             â”‚\n",
    "â”‚                                           local_kv, remote_kv)   â”‚\n",
    "â”‚                                                                  â”‚\n",
    "â”‚  6. Wait for read request            6. Post transfer            â”‚\n",
    "â”‚     (RDMA read from remote)             postXferReq(req)         â”‚\n",
    "â”‚                                                                  â”‚\n",
    "â”‚  7. â—€â•â•â•â•â•â•â• RDMA DATA â•â•â•â•â•â•â•â•â•â•â–¶   7. Poll for completion      â”‚\n",
    "â”‚     (Direct GPU-to-GPU)                 while IN_PROG:           â”‚\n",
    "â”‚                                           getXferStatus(req)     â”‚\n",
    "â”‚                                                                  â”‚\n",
    "â”‚  8. Send notification                8. Receive notification     â”‚\n",
    "â”‚     genNotif(\"kv_ready\")                getNotifs() â†’ \"kv_ready\" â”‚\n",
    "â”‚                                                                  â”‚\n",
    "â”‚                                      9. Use KV cache for decode  â”‚\n",
    "â”‚                                                                  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\"\"\"\n",
    "print(flow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 8: See NIXL in Action (Dynamo Logs)\n",
    "\n",
    "Let's look at NIXL activity in the Dynamo worker logs from Module 02."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"NIXL IN DYNAMO LOGS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "log_files = ['/tmp/dynamo_prefill.log', '/tmp/dynamo_decode.log']\n",
    "\n",
    "for log_file in log_files:\n",
    "    if os.path.exists(log_file):\n",
    "        worker_type = \"PREFILL\" if \"prefill\" in log_file else \"DECODE\"\n",
    "        print(f\"\\n{'ğŸ”µ' if worker_type == 'PREFILL' else 'ğŸŸ¢'} {worker_type} Worker NIXL activity:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        with open(log_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            nixl_lines = [l.strip() for l in lines if 'NIXL' in l.upper() or 'nixl' in l.lower()]\n",
    "            \n",
    "            if nixl_lines:\n",
    "                for line in nixl_lines[:10]:  # Show first 10 NIXL-related lines\n",
    "                    # Clean up the line for display\n",
    "                    if len(line) > 100:\n",
    "                        line = line[:100] + \"...\"\n",
    "                    print(f\"  {line}\")\n",
    "            else:\n",
    "                print(\"  No NIXL log entries found\")\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸  Log file not found: {log_file}\")\n",
    "        print(\"   Run Module 02 first to generate logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 9: NIXL Performance Characteristics\n",
    "\n",
    "Understanding when NIXL provides benefits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"NIXL PERFORMANCE CHARACTERISTICS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\"\"\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    Transfer Method Comparison                   â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ Method           â”‚ Bandwidth       â”‚ Latency                   â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ NIXL + NVLink    â”‚ ~600 GB/s       â”‚ ~1-2 Î¼s (same node)       â”‚\n",
    "â”‚ NIXL + RDMA      â”‚ ~25-100 GB/s    â”‚ ~2-5 Î¼s (cross node)      â”‚\n",
    "â”‚ NIXL + PCIe      â”‚ ~25-32 GB/s     â”‚ ~5-10 Î¼s                  â”‚\n",
    "â”‚ CPU Copy         â”‚ ~10-20 GB/s     â”‚ ~50-100 Î¼s (memcpy)       â”‚\n",
    "â”‚ TCP/IP           â”‚ ~1-10 GB/s      â”‚ ~100+ Î¼s                  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "Key Benefits of NIXL:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "âœ“ Zero-copy: Data goes directly GPUâ†’GPU without CPU involvement\n",
    "âœ“ Async: Transfers happen in background while GPU computes\n",
    "âœ“ Batched: Multiple memory regions can be transferred together\n",
    "âœ“ Unified: Same API for local (NVLink) and remote (RDMA) transfers\n",
    "\n",
    "When NIXL Matters Most:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "â€¢ Large KV caches (longer context = more data to transfer)\n",
    "â€¢ High request throughput (many transfers per second)\n",
    "â€¢ Multi-node deployments (cross-machine transfers)\n",
    "â€¢ Mixed prefill/decode ratios (frequent KV cache handoffs)\n",
    "\"\"\")\n",
    "\n",
    "# Calculate example transfer times\n",
    "kv_cache_sizes_gb = [1, 4, 16, 64]\n",
    "print(\"\\nğŸ“Š Example KV Cache Transfer Times:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'KV Cache Size':<15} {'RDMA (50GB/s)':<18} {'CPU Copy (15GB/s)':<18}\")\n",
    "print(\"-\" * 50)\n",
    "for size in kv_cache_sizes_gb:\n",
    "    rdma_time = size / 50 * 1000  # ms\n",
    "    cpu_time = size / 15 * 1000   # ms\n",
    "    print(f\"{size} GB{'':<10} {rdma_time:.1f} ms{'':<12} {cpu_time:.1f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 10: How Dynamo Uses NIXL\n",
    "\n",
    "Let's trace how Dynamo integrates NIXL for disaggregated serving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"DYNAMO + NIXL INTEGRATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\"\"\n",
    "Dynamo wraps NIXL in a higher-level abstraction:\n",
    "\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                     Dynamo Architecture                          â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                  â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚\n",
    "â”‚  â”‚                  dynamo.sglang Worker                    â”‚    â”‚\n",
    "â”‚  â”‚  --disaggregation-mode prefill/decode                    â”‚    â”‚\n",
    "â”‚  â”‚  --disaggregation-transfer-backend nixl                  â”‚    â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚\n",
    "â”‚                              â”‚                                   â”‚\n",
    "â”‚                              â–¼                                   â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚\n",
    "â”‚  â”‚              dynamo.nixl_connect Module                  â”‚    â”‚\n",
    "â”‚  â”‚  â€¢ Manages NIXL agent lifecycle                          â”‚    â”‚\n",
    "â”‚  â”‚  â€¢ Handles metadata exchange via bootstrap server        â”‚    â”‚\n",
    "â”‚  â”‚  â€¢ Coordinates KV cache transfers                        â”‚    â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚\n",
    "â”‚                              â”‚                                   â”‚\n",
    "â”‚                              â–¼                                   â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚\n",
    "â”‚  â”‚                    NIXL Library                          â”‚    â”‚\n",
    "â”‚  â”‚  nixlAgent â†’ UCX Backend â†’ RDMA/NVLink Hardware         â”‚    â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚\n",
    "â”‚                                                                  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "Key Dynamo Flags:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "  --disaggregation-transfer-backend nixl   # Use NIXL for transfers\n",
    "  --disaggregation-transfer-backend mooncake  # Alternative backend\n",
    "  --host 0.0.0.0                           # Required for bootstrap server\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **NIXL** is NVIDIA's library for high-performance point-to-point data transfers\n",
    "2. **nixlAgent** is the core class - each worker creates one to participate in transfers\n",
    "3. **UCX backend** provides RDMA support for GPU-direct transfers\n",
    "4. **Memory registration** is required before transfers (enables RDMA mappings)\n",
    "5. **Metadata exchange** allows agents to discover each other's memory layout\n",
    "6. **Async transfers** let GPU continue computing while data moves\n",
    "7. **Dynamo wraps NIXL** in the `--disaggregation-transfer-backend nixl` flag\n",
    "\n",
    "### Resources\n",
    "\n",
    "| Resource | URL |\n",
    "|----------|-----|\n",
    "| NIXL GitHub | https://github.com/ai-dynamo/nixl |\n",
    "| NIXL Docs | https://github.com/ai-dynamo/nixl/blob/main/docs/nixl.md |\n",
    "| vLLM NIXL Guide | https://docs.vllm.ai/en/stable/features/nixl_connector_usage/ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up GPU memory\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    print(\"âœ“ GPU memory cleared\")\n",
    "\n",
    "# The agent will be garbage collected automatically\n",
    "print(\"âœ“ Cleanup complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
