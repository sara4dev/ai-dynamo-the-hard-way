# AI Dynamo: The Hard Way

A progressive, hands-on approach to learning [NVIDIA AI Dynamo](https://github.com/ai-dynamo/dynamo) - a Datacenter Scale Distributed Inference Serving Framework.

> **Philosophy**: No Kubernetes operators. No magic. Just understanding each component from the ground up.
>
> **Key Learning Approach**: First measure baseline performance (without Dynamo), then demonstrate improvements with Dynamo. You can't appreciate optimizations without understanding what you're optimizing from.

## ğŸ–¥ï¸ Hardware Setup

| Node             | Hardware   | Purpose                             |
| ---------------- | ---------- | ----------------------------------- |
| **dgx-spark-01** | DGX Spark  | Primary node, Frontend, Workers     |
| **dgx-spark-02** | DGX Spark  | Secondary node, Distributed workers |
| **Network**      | InfiniBand | RDMA for NIXL KV cache transfer     |

This setup is ideal for learning Dynamo because its key innovations (disaggregated serving, NIXL, cross-node inference) require multi-node + InfiniBand.

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        AI Dynamo Architecture                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚   Clients    â”‚â”€â”€â”€â”€â–¶â”‚   Frontend   â”‚â”€â”€â”€â”€â–¶â”‚     Router       â”‚    â”‚
â”‚  â”‚  (OpenAI API)â”‚     â”‚  (Rust HTTP) â”‚     â”‚ (Basic/KV-Aware) â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                     â”‚              â”‚
â”‚                                                     â–¼              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                          Workers                           â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚    â”‚
â”‚  â”‚  â”‚  SGLang   â”‚    â”‚  TensorRT-LLM â”‚    â”‚     vLLM      â”‚   â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                       Infrastructure                         â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚
â”‚  â”‚  â”‚    etcd     â”‚    â”‚    NATS     â”‚    â”‚   NIXL (RDMA)   â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  (Service   â”‚    â”‚ (Messaging/ â”‚    â”‚   (KV Cache     â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  Discovery) â”‚    â”‚  JetStream) â”‚    â”‚    Transfer)    â”‚   â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“š Learning Modules

### Part 1: Foundations (Single Node - dgx-spark-01)

| Module | Notebook                                                                           | Description                                  |
| ------ | ---------------------------------------------------------------------------------- | -------------------------------------------- |
| **00** | [00-architecture-overview.ipynb](notebooks/00-architecture-overview.ipynb)         | Understand Dynamo's components and data flow |
| **01** | [01-setup-and-first-inference.ipynb](notebooks/01-setup-and-first-inference.ipynb) | Install Dynamo, first inference request      |
| **02** | [02-frontend-deep-dive.ipynb](notebooks/02-frontend-deep-dive.ipynb)               | Rust HTTP server, OpenAI compatibility       |
| **03** | [03-workers-and-backends.ipynb](notebooks/03-workers-and-backends.ipynb)           | SGLang, vLLM, TensorRT-LLM comparison        |

### Part 2: Infrastructure (Single Node)

| Module | Notebook                                                                     | Description                             |
| ------ | ---------------------------------------------------------------------------- | --------------------------------------- |
| **04** | [04-etcd-service-discovery.ipynb](notebooks/04-etcd-service-discovery.ipynb) | Manual etcd setup, service registration |
| **05** | [05-nats-messaging.ipynb](notebooks/05-nats-messaging.ipynb)                 | NATS JetStream for KV cache events      |
| **06** | [06-kv-aware-routing.ipynb](notebooks/06-kv-aware-routing.ipynb)             | Prefix caching, smart request routing   |

### Part 3: Distributed Inference (Both DGX Spark Nodes)

| Module | Notebook                                                                           | Description                                     |
| ------ | ---------------------------------------------------------------------------------- | ----------------------------------------------- |
| **07** | [07-infiniband-setup.ipynb](notebooks/07-infiniband-setup.ipynb)                   | Verify InfiniBand, RDMA configuration           |
| **08** | [08-multi-node-workers.ipynb](notebooks/08-multi-node-workers.ipynb)               | Workers across nodes, pipeline parallelism      |
| **09** | [09-baseline-two-node-serving.ipynb](notebooks/09-baseline-two-node-serving.ipynb) | **Baseline**: Two vLLM nodes without Dynamo     |
| **10** | [10-disaggregated-serving.ipynb](notebooks/10-disaggregated-serving.ipynb)         | **With Dynamo**: Same nodes, disaggregated mode |
| **11** | [11-nixl-kv-transfer.ipynb](notebooks/11-nixl-kv-transfer.ipynb)                   | RDMA-based KV cache transfer                    |

### Part 4: Production Patterns

| Module | Notebook                                                                     | Description                             |
| ------ | ---------------------------------------------------------------------------- | --------------------------------------- |
| **12** | [12-benchmarking.ipynb](notebooks/12-benchmarking.ipynb)                     | AIPerf, latency analysis, throughput    |
| **13** | [13-large-model-deployment.ipynb](notebooks/13-large-model-deployment.ipynb) | DeepSeek-R1, Llama-3-70B across cluster |

## ğŸš€ Quick Start

```bash
# Clone this repository
git clone https://github.com/sara4dev/ai-dynamo-the-hard-way.git
cd ai-dynamo-the-hard-way

# Start with Module 00
jupyter lab notebooks/00-architecture-overview.ipynb
```

## ğŸ“‹ Prerequisites

- **Python**: 3.10+
- **CUDA**: 12.x+
- **Rust**: Latest stable (for building from source)
- **InfiniBand**: Configured between DGX Spark nodes
- **SSH**: Passwordless SSH between nodes

## ğŸ”— Key Resources

- [AI Dynamo GitHub](https://github.com/ai-dynamo/dynamo)
- [Official Documentation](https://docs.nvidia.com/dynamo/latest)
- [Dynamo v0.8.1 Release](https://github.com/ai-dynamo/dynamo/releases/tag/v0.8.1) (Latest as of Jan 2026)

## ğŸ“ Project Structure

```
ai-dynamo-the-hard-way/
â”œâ”€â”€ README.md
â”œâ”€â”€ notebooks/              # Jupyter notebooks for each module
â”‚   â”œâ”€â”€ 00-architecture-overview.ipynb
â”‚   â”œâ”€â”€ 01-setup-and-first-inference.ipynb
â”‚   â””â”€â”€ ...
â”œâ”€â”€ scripts/                # Helper scripts
â”‚   â”œâ”€â”€ install-dynamo.sh
â”‚   â”œâ”€â”€ start-etcd.sh
â”‚   â”œâ”€â”€ start-nats.sh
â”‚   â””â”€â”€ ...
â”œâ”€â”€ configs/                # Configuration files
â”‚   â”œâ”€â”€ etcd/
â”‚   â”œâ”€â”€ nats/
â”‚   â””â”€â”€ dynamo/
â””â”€â”€ inventory/              # Node inventory
    â””â”€â”€ hosts.yaml
```

## ğŸ“Š The Baseline Comparison (Modules 09-10)

A key learning experience in this curriculum is the **before/after comparison**:

| Metric              | Module 09 (Baseline)       | Module 10 (Dynamo)     | Why It Matters                |
| ------------------- | -------------------------- | ---------------------- | ----------------------------- |
| **Throughput**      | Two independent vLLM nodes | Same nodes with Dynamo | Shows specialization benefits |
| **TTFT**            | Higher variance            | Lower, consistent      | Dedicated prefill nodes help  |
| **p95 Latency**     | Higher tail latency        | Lower tail latency     | No prefill blocking decode    |
| **GPU Utilization** | Uneven, bursty             | Balanced, efficient    | Better resource allocation    |

This comparison answers the fundamental question: **"Why do we need Dynamo at all?"**

## ğŸ¯ Learning Outcomes

By the end of this journey, you will:

1. **Understand** Dynamo's architecture and how components interact
2. **Deploy** inference workers using multiple backends (SGLang, vLLM, TRT-LLM)
3. **Configure** service discovery with etcd manually
4. **Implement** messaging patterns with NATS JetStream
5. **Enable** KV-aware routing for efficient prefix caching
6. **Scale** inference across multiple nodes using InfiniBand
7. **Measure** baseline performance and demonstrate quantifiable improvements
8. **Optimize** with disaggregated prefill/decode serving
9. **Benchmark** and tune for production workloads

---

*"The hard way is the easy way in the long run."*
